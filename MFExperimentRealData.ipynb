{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc80e674",
   "metadata": {},
   "source": [
    "# Steps\n",
    "1. Make data choice.\n",
    "5. Choose 'fixed' configuration.\n",
    "6. For each 'fixed' configuration, optimize the other parameters based on RMSE.\n",
    "7. Given optimal setting, run popularity bias analysis for every version of the 'fixed' configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d29498",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d87f4ad4-cce3-418c-b189-324f9b6a7197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MKL_THREADING_LAYER=tbb\n",
      "env: OPENBLAS_NUM_THREADS=24\n",
      "env: NUMBA_NUM_THREADS=96\n",
      "env: MKL_NUM_THREADS=96\n",
      "env: OMP_NUM_THREADS=1\n"
     ]
    }
   ],
   "source": [
    "%env MKL_THREADING_LAYER=tbb\n",
    "%env OPENBLAS_NUM_THREADS=24\n",
    "%env NUMBA_NUM_THREADS=96\n",
    "%env MKL_NUM_THREADS=96\n",
    "%env OMP_NUM_THREADS=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "261f8b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"tbb\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"24\"\n",
    "os.environ[\"NUMBA_NUM_THREADS\"] = \"96\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"96\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "# for random generation\n",
    "\n",
    "\n",
    "# basic functions\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_rows = 100\n",
    "import pickle\n",
    "import scipy\n",
    "\n",
    "# custom-made functions\n",
    "import modelling_mf\n",
    "from optimize_hp import optimize_lkpy, optimize_cornac\n",
    "\n",
    "# lenskit RS library\n",
    "from lenskit.algorithms import als\n",
    "\n",
    "\n",
    "# cornac RS library\n",
    "from cornac.models import MF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cada525",
   "metadata": {},
   "source": [
    "## Data and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b93470ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"fairbook\"\n",
    "# user-item interactions\n",
    "fairbook_ratings = pd.read_csv(\"data/\" + data + \"_events.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53c071e3-8f6a-45af-b044-e3ca966e2222",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"ml1m\"\n",
    "# user-item interactions\n",
    "ml1m_ratings = pd.read_csv(\n",
    "    \"data/\" + data + \"_events.dat\", header=None, sep=\"::\", engine=\"python\"\n",
    ").drop(3, axis=1)\n",
    "ml1m_ratings.columns = [\"user\", \"item\", \"rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89248693-6210-4bbb-907d-af76e8da7111",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"epinion\"\n",
    "mat = scipy.io.loadmat(\"data/\" + data + \"_events.mat\")\n",
    "mat_df = pd.DataFrame(mat[\"rating_with_timestamp\"])\n",
    "mat_df.columns = [\"user\", \"item\", \".\", \"rating\", \"..\", \"...\"]\n",
    "epinion_ratings = mat_df[[\"user\", \"item\", \"rating\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8685e42b-e5ec-4032-9045-9549de9f64b5",
   "metadata": {},
   "source": [
    "Make data choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3885594-8ab9-4f0b-aa66-322bfe86e633",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = epinion_ratings.copy()\n",
    "ratings = ratings.drop_duplicates(subset=[\"user\", \"item\"], keep=\"last\")\n",
    "data_strategy = \"epinion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "940275c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_col = \"user\"  # the name of the column that includes the users\n",
    "item_col = \"item\"  # the name of the column that includes the items\n",
    "predict_col = \"rating\"  # the name of the column that includes the interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d390e90-3c0b-4678-bae1-8a6438b55eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_way = \"cross_validation\"\n",
    "verbose = True\n",
    "plot = True\n",
    "save_plot = True  # save the plots\n",
    "fallback = False\n",
    "nr_recs = 10\n",
    "sampling_strategy = \"frac\"\n",
    "partition_way = \"user\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e535cae7",
   "metadata": {},
   "source": [
    "## Optimize, train, evaluate LKPY\n",
    "- **Algorithm**\n",
    "- **Fixed parameters**\n",
    "- **To-optimize parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b407cd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_versions = {\"MF\": [{\"bias\": True}, {\"bias\": False}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b31512c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bias': True}\n",
      "We got them already\n",
      "0 Training done!\n",
      "Prediction done!\n",
      "0 Recommendation done!\n",
      "nr of longtail 943\n",
      "0.21281877679981945\n",
      "1 Training done!\n",
      "Prediction done!\n",
      "1 Recommendation done!\n",
      "nr of longtail 939\n",
      "0.21186823104693142\n",
      "2 Training done!\n",
      "Prediction done!\n",
      "2 Recommendation done!\n",
      "nr of longtail 967\n",
      "0.21818592057761732\n",
      "3 Training done!\n",
      "Prediction done!\n",
      "3 Recommendation done!\n",
      "nr of longtail 885\n",
      "0.1997291807718348\n",
      "4 Training done!\n",
      "Prediction done!\n",
      "4 Recommendation done!\n",
      "nr of longtail 964\n",
      "0.21755811329271044\n"
     ]
    }
   ],
   "source": [
    "# choose algorithm\n",
    "algorithm_lkpy = als.BiasedMF\n",
    "algo_name = \"MF\"\n",
    "versions = algo_versions[algo_name]\n",
    "\n",
    "\n",
    "# for every 'fixed' version of the algorithm\n",
    "for args in versions:\n",
    "    print(args)\n",
    "\n",
    "\n",
    "    p = \"best_parameters/\" + algo_name + \"/\" + data_strategy + \"_\" + str(args) + \".pkl\"\n",
    "    if os.path.isfile(p):\n",
    "        print(\"We got them already\")\n",
    "        with open(p, \"rb\") as f:\n",
    "            best_params = pickle.load(f)\n",
    "    else:\n",
    "        print(\"We have to compute them now\")\n",
    "        # optimize for this fixed version\n",
    "        best_params = optimize_lkpy(\n",
    "            ratings=ratings, algorithm_name=algo_name, args=args, max_evals=20, partition_way = 'row'\n",
    "        )\n",
    "\n",
    "        # save the best parameters for this fixed version\n",
    "\n",
    "        with open(\n",
    "            \"best_parameters/\"\n",
    "            + algo_name\n",
    "            + \"/\"\n",
    "            + data_strategy\n",
    "            + \"_\"\n",
    "            + str(args)\n",
    "            + \".pkl\",\n",
    "            \"wb\",\n",
    "        ) as f:\n",
    "            pickle.dump(best_params, f)\n",
    "    \n",
    "    # # optimize for this fixed version\n",
    "    # best_params = optimize_lkpy(\n",
    "    #     ratings=ratings,\n",
    "    #     algorithm_name=algo_name,\n",
    "    #     args=args,\n",
    "    #     partition_way=\"row\",\n",
    "    #     max_evals=20,\n",
    "    # )\n",
    "\n",
    "    # # save the best parameters for this fixed version\n",
    "\n",
    "    # with open(\n",
    "    #     \"best_parameters/\" + algo_name + \"/\" + data_strategy + \"_\" + str(args) + \".pkl\",\n",
    "    #     \"wb\",\n",
    "    # ) as f:\n",
    "    #     pickle.dump(best_params, f)\n",
    "\n",
    "    reg_list = [0, 0.001, 0.01, 0.1]\n",
    "    features_list = [10, 50, 100]\n",
    "    optimal_reg = reg_list[best_params[\"reg\"]]\n",
    "    optimal_features = features_list[best_params[\"features\"]]\n",
    "\n",
    "    # run the training and evaluation for the fixed version + the best other parameters\n",
    "    pop_biases_lkpy, metrics_dict_lkpy = modelling_mf.train_algorithm(\n",
    "        algorithm=algorithm_lkpy(\n",
    "            features=optimal_features, reg=optimal_reg, bias=args[\"bias\"]\n",
    "        ),\n",
    "        algo_name=algo_name,\n",
    "        ratings=ratings,\n",
    "        evaluation_way=evaluation_way,\n",
    "        verbose=verbose,\n",
    "        n=nr_recs,\n",
    "        sampling_strategy=sampling_strategy,\n",
    "        partition_way=partition_way,\n",
    "        plot=plot,\n",
    "        data_strategy=data_strategy,\n",
    "        args=args,\n",
    "        save_plot=save_plot,\n",
    "    )\n",
    "\n",
    "    # Save metrics!\n",
    "    with open(\n",
    "        \"experimental_results/\"\n",
    "        + algo_name\n",
    "        + \"/\"\n",
    "        + data_strategy\n",
    "        + \"_\"\n",
    "        + str(args)\n",
    "        + \".pkl\",\n",
    "        \"wb\",\n",
    "    ) as f:\n",
    "        pickle.dump(metrics_dict_lkpy, f)\n",
    "    with open('experimental_results/'+algo_name+'/detailed_per_item_'+data_strategy+'_'+str(args)+'.pkl', 'wb') as f:\n",
    "        pickle.dump(pop_biases_lkpy, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12c2a15-73df-4d93-885d-bf76084714f2",
   "metadata": {},
   "source": [
    "## Optimize, train, evaluate Cornac\n",
    "- **Algorithm**\n",
    "- **Fixed parameters**\n",
    "- **To-optimize parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "182fa673-122f-40df-a9e9-32f940f51e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {}  # Create a dictionary that maps each item to an integer - necessary for Cornac.\n",
    "i = 0\n",
    "for mov in ratings[item_col].unique():\n",
    "    mapping_dict[mov] = i\n",
    "    i += 1\n",
    "ratings[item_col] = ratings[item_col].map(\n",
    "    lambda x: mapping_dict.get(x, x)\n",
    ")  # Map in the ratings file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ca6a8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_versions = {\"CornacMF\": [{\"bias\": True}, {\"bias\": False}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bba024d-1f1e-4b33-981c-32d443eec2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epinion {'bias': True}\n",
      "We got them already\n",
      "\n",
      "TEST:\n",
      "...\n",
      "   |   RMSE | Train (s) | Test (s)\n",
      "-- + ------ + --------- + --------\n",
      "MF | 1.0317 |    2.1678 |   0.4742\n",
      "\n",
      "Training done!\n",
      "Recommendation done!\n",
      "nr of longtail 0\n",
      "0.0\n",
      "\n",
      "TEST:\n",
      "...\n",
      "   |   RMSE | Train (s) | Test (s)\n",
      "-- + ------ + --------- + --------\n",
      "MF | 1.0192 |    1.3660 |   0.4935\n",
      "\n",
      "Training done!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (289169,) into shape (288910,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m optimal_reg \u001b[38;5;241m=\u001b[39m best_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlambda_reg\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     38\u001b[0m optimal_lr \u001b[38;5;241m=\u001b[39m best_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 40\u001b[0m pop_biases_cornac, metrics_dict_cornac \u001b[38;5;241m=\u001b[39m \u001b[43mmodelling_mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_algorithm_cornac\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgorithm_cornac\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimal_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlambda_reg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimal_reg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimal_lr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mratings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mratings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluation_way\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluation_way\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnr_recs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampling_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartition_way\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_way\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_plot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_plot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Save metrics!\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperimental_results/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;241m+\u001b[39m algo_name\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     70\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/new_environment/DiagnosingBiasRecSys/modelling_mf.py:498\u001b[0m, in \u001b[0;36mtrain_algorithm_cornac\u001b[0;34m(algorithm, algo_name, ratings, evaluation_way, partition_way, sampling_strategy, verbose, min_sim, user_col, item_col, predict_col, n, plot, args, data_strategy, save_plot)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining done!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    497\u001b[0m test_users \u001b[38;5;241m=\u001b[39m test_df\u001b[38;5;241m.\u001b[39muser\u001b[38;5;241m.\u001b[39munique()  \u001b[38;5;66;03m# the users in the test set\u001b[39;00m\n\u001b[0;32m--> 498\u001b[0m recs, stdev_20 \u001b[38;5;241m=\u001b[39m \u001b[43mrecommend_cornac\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_items\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mitem_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m recs_grouped \u001b[38;5;241m=\u001b[39m recs\u001b[38;5;241m.\u001b[39mgroupby([user_col])[item_col]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m    502\u001b[0m total_stdev_20 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m stdev_20\n",
      "File \u001b[0;32m~/new_environment/DiagnosingBiasRecSys/modelling_mf.py:308\u001b[0m, in \u001b[0;36mrecommend_cornac\u001b[0;34m(exp, all_items, user_col, item_col, n)\u001b[0m\n\u001b[1;32m    303\u001b[0m user_items_not_in_the_train_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    304\u001b[0m     all_items\u001b[38;5;241m.\u001b[39mdifference(user_items_in_the_train_set)\n\u001b[1;32m    305\u001b[0m )\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# print(user_id, len(user_items_not_in_the_train_set))\u001b[39;00m\n\u001b[0;32m--> 308\u001b[0m item_rank \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrank\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_items_not_in_the_train_set\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# items the user has NOT rated in the TRAIN set\u001b[39;00m\n\u001b[1;32m    312\u001b[0m item_rank_top \u001b[38;5;241m=\u001b[39m item_rank[:n]\n\u001b[1;32m    313\u001b[0m rec_items \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/new_environment/conda/envs/biasenv/lib/python3.8/site-packages/cornac/models/recommender.py:283\u001b[0m, in \u001b[0;36mRecommender.rank\u001b[0;34m(self, user_idx, item_indices)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    280\u001b[0m     all_item_scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_set\u001b[38;5;241m.\u001b[39mtotal_items) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(\n\u001b[1;32m    281\u001b[0m         known_item_scores\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 283\u001b[0m     \u001b[43mall_item_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_items\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m known_item_scores\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m# rank items based on their scores\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m item_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (289169,) into shape (288910,)"
     ]
    }
   ],
   "source": [
    "algorithm_cornac = MF\n",
    "algo_name = \"CornacMF\"\n",
    "versions = algo_versions[algo_name]\n",
    "\n",
    "\n",
    "# for every 'fixed' version of the algorithm\n",
    "for args in versions:\n",
    "    print(data_strategy, args)\n",
    "\n",
    "    p = \"best_parameters/\" + algo_name + \"/\" + data_strategy + \"_\" + str(args) + \".pkl\"\n",
    "    if os.path.isfile(p):\n",
    "        print(\"We got them already\")\n",
    "        with open(p, \"rb\") as f:\n",
    "            best_params = pickle.load(f)\n",
    "    else:\n",
    "        print(\"We have to compute them now\")\n",
    "        # optimize for this fixed version\n",
    "        best_params = optimize_cornac(\n",
    "            ratings=ratings, algorithm_name=algo_name, args=args, max_evals=20\n",
    "        )\n",
    "\n",
    "        # save the best parameters for this fixed version\n",
    "\n",
    "        with open(\n",
    "            \"best_parameters/\"\n",
    "            + algo_name\n",
    "            + \"/\"\n",
    "            + data_strategy\n",
    "            + \"_\"\n",
    "            + str(args)\n",
    "            + \".pkl\",\n",
    "            \"wb\",\n",
    "        ) as f:\n",
    "            pickle.dump(best_params, f)\n",
    "\n",
    "    optimal_k = best_params[\"k\"]\n",
    "    optimal_reg = best_params[\"lambda_reg\"]\n",
    "    optimal_lr = best_params[\"learning_rate\"]\n",
    "\n",
    "    pop_biases_cornac, metrics_dict_cornac = modelling_mf.train_algorithm_cornac(\n",
    "        algorithm=algorithm_cornac(\n",
    "            k=optimal_k,\n",
    "            use_bias=args[\"bias\"],\n",
    "            lambda_reg=optimal_reg,\n",
    "            learning_rate=optimal_lr,\n",
    "        ),\n",
    "        algo_name=algo_name,\n",
    "        ratings=ratings,\n",
    "        evaluation_way=evaluation_way,\n",
    "        verbose=verbose,\n",
    "        n=nr_recs,\n",
    "        sampling_strategy=sampling_strategy,\n",
    "        partition_way=partition_way,\n",
    "        plot=plot,\n",
    "        data_strategy=data_strategy,\n",
    "        args=args,\n",
    "        save_plot=save_plot,\n",
    "    )\n",
    "\n",
    "    # Save metrics!\n",
    "    with open(\n",
    "        \"experimental_results/\"\n",
    "        + algo_name\n",
    "        + \"/\"\n",
    "        + data_strategy\n",
    "        + \"_\"\n",
    "        + str(args)\n",
    "        + \".pkl\",\n",
    "        \"wb\",\n",
    "    ) as f:\n",
    "        pickle.dump(metrics_dict_cornac, f)\n",
    "    with open('experimental_results/'+algo_name+'/detailed_per_item_'+data_strategy+'_'+str(args)+'.pkl', 'wb') as f:\n",
    "        pickle.dump(pop_biases_cornac, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c3278b04384a1f2d1b0bc3e8783905713abb1db8d84b3b69ddff13fab40f022"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
