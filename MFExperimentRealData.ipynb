{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc80e674",
   "metadata": {},
   "source": [
    "# Steps\n",
    "1. Make data choice.\n",
    "5. Choose 'fixed' configuration.\n",
    "6. For each 'fixed' configuration, optimize the other parameters based on RMSE.\n",
    "7. Given optimal setting, run popularity bias analysis for every version of the 'fixed' configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d29498",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d87f4ad4-cce3-418c-b189-324f9b6a7197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MKL_THREADING_LAYER=tbb\n",
      "env: OPENBLAS_NUM_THREADS=24\n",
      "env: NUMBA_NUM_THREADS=96\n",
      "env: MKL_NUM_THREADS=96\n",
      "env: OMP_NUM_THREADS=1\n"
     ]
    }
   ],
   "source": [
    "%env MKL_THREADING_LAYER=tbb\n",
    "%env OPENBLAS_NUM_THREADS=24\n",
    "%env NUMBA_NUM_THREADS=96\n",
    "%env MKL_NUM_THREADS=96\n",
    "%env OMP_NUM_THREADS=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "261f8b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"tbb\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"24\"\n",
    "os.environ[\"NUMBA_NUM_THREADS\"] = \"96\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"96\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "# for random generation\n",
    "\n",
    "\n",
    "# basic functions\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_rows = 100\n",
    "import pickle\n",
    "import scipy\n",
    "\n",
    "# custom-made functions\n",
    "import modelling_mf\n",
    "from optimize_hp import optimize_lkpy, optimize_cornac\n",
    "\n",
    "# lenskit RS library\n",
    "from lenskit.algorithms import als\n",
    "\n",
    "\n",
    "# cornac RS library\n",
    "from cornac.models import MF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cada525",
   "metadata": {},
   "source": [
    "## Data and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b93470ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"fairbook\"\n",
    "# user-item interactions\n",
    "fairbook_ratings = pd.read_csv(\"data/\" + data + \"_events.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53c071e3-8f6a-45af-b044-e3ca966e2222",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"ml1m\"\n",
    "# user-item interactions\n",
    "ml1m_ratings = pd.read_csv(\n",
    "    \"data/\" + data + \"_events.dat\", header=None, sep=\"::\", engine=\"python\"\n",
    ").drop(3, axis=1)\n",
    "ml1m_ratings.columns = [\"user\", \"item\", \"rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89248693-6210-4bbb-907d-af76e8da7111",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"epinion\"\n",
    "mat = scipy.io.loadmat(\"data/\" + data + \"_events.mat\")\n",
    "mat_df = pd.DataFrame(mat[\"rating_with_timestamp\"])\n",
    "mat_df.columns = [\"user\", \"item\", \".\", \"rating\", \"..\", \"...\"]\n",
    "epinion_ratings = mat_df[[\"user\", \"item\", \"rating\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8685e42b-e5ec-4032-9045-9549de9f64b5",
   "metadata": {},
   "source": [
    "Make data choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3885594-8ab9-4f0b-aa66-322bfe86e633",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ml1m_ratings.copy()\n",
    "ratings = ratings.drop_duplicates(subset=[\"user\", \"item\"], keep=\"last\")\n",
    "data_strategy = \"ml1m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "940275c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_col = \"user\"  # the name of the column that includes the users\n",
    "item_col = \"item\"  # the name of the column that includes the items\n",
    "predict_col = \"rating\"  # the name of the column that includes the interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d390e90-3c0b-4678-bae1-8a6438b55eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_way = \"cross_validation\"\n",
    "verbose = True\n",
    "plot = True\n",
    "save_plot = True  # save the plots\n",
    "fallback = False\n",
    "nr_recs = 10\n",
    "sampling_strategy = \"frac\"\n",
    "partition_way = \"user\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e535cae7",
   "metadata": {},
   "source": [
    "## Optimize, train, evaluate LKPY\n",
    "- **Algorithm**\n",
    "- **Fixed parameters**\n",
    "- **To-optimize parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b407cd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_versions = {\"MF\": [{\"bias\": True}, {\"bias\": False}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b31512c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bias': True}\n",
      "We got them already\n",
      "0 Training done!\n",
      "Prediction done!\n",
      "0 Recommendation done!\n",
      "nr of longtail 943\n",
      "0.21281877679981945\n",
      "1 Training done!\n",
      "Prediction done!\n",
      "1 Recommendation done!\n",
      "nr of longtail 939\n",
      "0.21186823104693142\n",
      "2 Training done!\n",
      "Prediction done!\n",
      "2 Recommendation done!\n",
      "nr of longtail 967\n",
      "0.21818592057761732\n",
      "3 Training done!\n",
      "Prediction done!\n",
      "3 Recommendation done!\n",
      "nr of longtail 885\n",
      "0.1997291807718348\n",
      "4 Training done!\n",
      "Prediction done!\n",
      "4 Recommendation done!\n",
      "nr of longtail 964\n",
      "0.21755811329271044\n"
     ]
    }
   ],
   "source": [
    "# choose algorithm\n",
    "algorithm_lkpy = als.BiasedMF\n",
    "algo_name = \"MF\"\n",
    "versions = algo_versions[algo_name]\n",
    "\n",
    "\n",
    "# for every 'fixed' version of the algorithm\n",
    "for args in versions:\n",
    "    print(args)\n",
    "\n",
    "\n",
    "    p = \"best_parameters/\" + algo_name + \"/\" + data_strategy + \"_\" + str(args) + \".pkl\"\n",
    "    if os.path.isfile(p):\n",
    "        print(\"We got them already\")\n",
    "        with open(p, \"rb\") as f:\n",
    "            best_params = pickle.load(f)\n",
    "    else:\n",
    "        print(\"We have to compute them now\")\n",
    "        # optimize for this fixed version\n",
    "        best_params = optimize_lkpy(\n",
    "            ratings=ratings, algorithm_name=algo_name, args=args, max_evals=20, partition_way = 'row'\n",
    "        )\n",
    "\n",
    "        # save the best parameters for this fixed version\n",
    "\n",
    "        with open(\n",
    "            \"best_parameters/\"\n",
    "            + algo_name\n",
    "            + \"/\"\n",
    "            + data_strategy\n",
    "            + \"_\"\n",
    "            + str(args)\n",
    "            + \".pkl\",\n",
    "            \"wb\",\n",
    "        ) as f:\n",
    "            pickle.dump(best_params, f)\n",
    "    \n",
    "    # # optimize for this fixed version\n",
    "    # best_params = optimize_lkpy(\n",
    "    #     ratings=ratings,\n",
    "    #     algorithm_name=algo_name,\n",
    "    #     args=args,\n",
    "    #     partition_way=\"row\",\n",
    "    #     max_evals=20,\n",
    "    # )\n",
    "\n",
    "    # # save the best parameters for this fixed version\n",
    "\n",
    "    # with open(\n",
    "    #     \"best_parameters/\" + algo_name + \"/\" + data_strategy + \"_\" + str(args) + \".pkl\",\n",
    "    #     \"wb\",\n",
    "    # ) as f:\n",
    "    #     pickle.dump(best_params, f)\n",
    "\n",
    "    reg_list = [0, 0.001, 0.01, 0.1]\n",
    "    features_list = [10, 50, 100]\n",
    "    optimal_reg = reg_list[best_params[\"reg\"]]\n",
    "    optimal_features = features_list[best_params[\"features\"]]\n",
    "\n",
    "    # run the training and evaluation for the fixed version + the best other parameters\n",
    "    pop_biases_lkpy, metrics_dict_lkpy = modelling_mf.train_algorithm(\n",
    "        algorithm=algorithm_lkpy(\n",
    "            features=optimal_features, reg=optimal_reg, bias=args[\"bias\"]\n",
    "        ),\n",
    "        algo_name=algo_name,\n",
    "        ratings=ratings,\n",
    "        evaluation_way=evaluation_way,\n",
    "        verbose=verbose,\n",
    "        n=nr_recs,\n",
    "        sampling_strategy=sampling_strategy,\n",
    "        partition_way=partition_way,\n",
    "        plot=plot,\n",
    "        data_strategy=data_strategy,\n",
    "        args=args,\n",
    "        save_plot=save_plot,\n",
    "    )\n",
    "\n",
    "    # Save metrics!\n",
    "    with open(\n",
    "        \"experimental_results/\"\n",
    "        + algo_name\n",
    "        + \"/\"\n",
    "        + data_strategy\n",
    "        + \"_\"\n",
    "        + str(args)\n",
    "        + \".pkl\",\n",
    "        \"wb\",\n",
    "    ) as f:\n",
    "        pickle.dump(metrics_dict_lkpy, f)\n",
    "    with open('experimental_results/'+algo_name+'/detailed_per_item_'+data_strategy+'_'+str(args)+'.pkl', 'wb') as f:\n",
    "        pickle.dump(pop_biases_lkpy, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12c2a15-73df-4d93-885d-bf76084714f2",
   "metadata": {},
   "source": [
    "## Optimize, train, evaluate Cornac\n",
    "- **Algorithm**\n",
    "- **Fixed parameters**\n",
    "- **To-optimize parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "182fa673-122f-40df-a9e9-32f940f51e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {}  # Create a dictionary that maps each item to an integer - necessary for Cornac.\n",
    "i = 0\n",
    "for mov in ratings[item_col].unique():\n",
    "    mapping_dict[mov] = i\n",
    "    i += 1\n",
    "ratings[item_col] = ratings[item_col].map(\n",
    "    lambda x: mapping_dict.get(x, x)\n",
    ")  # Map in the ratings file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ca6a8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_versions = {\"CornacMF\": [{\"bias\": True}, {\"bias\": False}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bba024d-1f1e-4b33-981c-32d443eec2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml1m {'bias': True}\n",
      "We got them already\n",
      "         user  item  rating\n",
      "0           1     0       5\n",
      "1           1     1       3\n",
      "2           1     2       3\n",
      "3           1     3       4\n",
      "4           1     4       5\n",
      "...       ...   ...     ...\n",
      "1000204  6040   772       1\n",
      "1000205  6040  1106       5\n",
      "1000206  6040   365       5\n",
      "1000207  6040   152       4\n",
      "1000208  6040    26       4\n",
      "\n",
      "[960931 rows x 3 columns]\n",
      "Splits made!\n",
      "Experiment made!\n",
      "\n",
      "TEST:\n",
      "...\n",
      "   |   RMSE | Train (s) | Test (s)\n",
      "-- + ------ + --------- + --------\n",
      "MF | 0.8424 |    1.0463 |   0.5744\n",
      "\n",
      "Experiment ran!\n",
      "Training done!\n",
      "Recommendation done!\n",
      "Pop bias!\n",
      "GAP GAP!\n",
      "nr of longtail 2573\n",
      "2.1299668874172184\n",
      "all metrics!\n",
      "         user  item  rating\n",
      "0           1     0       5\n",
      "1           1     1       3\n",
      "2           1     2       3\n",
      "3           1     3       4\n",
      "4           1     4       5\n",
      "...       ...   ...     ...\n",
      "1000204  6040   772       1\n",
      "1000205  6040  1106       5\n",
      "1000206  6040   365       5\n",
      "1000207  6040   152       4\n",
      "1000208  6040    26       4\n",
      "\n",
      "[960765 rows x 3 columns]\n",
      "Splits made!\n",
      "Experiment made!\n",
      "\n",
      "TEST:\n",
      "...\n",
      "   |   RMSE | Train (s) | Test (s)\n",
      "-- + ------ + --------- + --------\n",
      "MF | 0.8474 |    1.3173 |   0.5528\n",
      "\n",
      "Experiment ran!\n",
      "Training done!\n",
      "Recommendation done!\n",
      "Pop bias!\n",
      "GAP GAP!\n",
      "nr of longtail 1017\n",
      "0.8418874172185431\n",
      "all metrics!\n",
      "         user  item  rating\n",
      "0           1     0       5\n",
      "1           1     1       3\n",
      "2           1     2       3\n",
      "3           1     3       4\n",
      "4           1     4       5\n",
      "...       ...   ...     ...\n",
      "1000204  6040   772       1\n",
      "1000205  6040  1106       5\n",
      "1000206  6040   365       5\n",
      "1000207  6040   152       4\n",
      "1000208  6040    26       4\n",
      "\n",
      "[961956 rows x 3 columns]\n",
      "Splits made!\n",
      "Experiment made!\n"
     ]
    }
   ],
   "source": [
    "algorithm_cornac = MF\n",
    "algo_name = \"CornacMF\"\n",
    "versions = algo_versions[algo_name]\n",
    "\n",
    "\n",
    "# for every 'fixed' version of the algorithm\n",
    "for args in versions:\n",
    "    print(data_strategy, args)\n",
    "\n",
    "    p = \"best_parameters/\" + algo_name + \"/\" + data_strategy + \"_\" + str(args) + \".pkl\"\n",
    "    if os.path.isfile(p):\n",
    "        print(\"We got them already\")\n",
    "        with open(p, \"rb\") as f:\n",
    "            best_params = pickle.load(f)\n",
    "    else:\n",
    "        print(\"We have to compute them now\")\n",
    "        # optimize for this fixed version\n",
    "        best_params = optimize_cornac(\n",
    "            ratings=ratings, algorithm_name=algo_name, args=args, max_evals=20\n",
    "        )\n",
    "\n",
    "        # save the best parameters for this fixed version\n",
    "\n",
    "        with open(\n",
    "            \"best_parameters/\"\n",
    "            + algo_name\n",
    "            + \"/\"\n",
    "            + data_strategy\n",
    "            + \"_\"\n",
    "            + str(args)\n",
    "            + \".pkl\",\n",
    "            \"wb\",\n",
    "        ) as f:\n",
    "            pickle.dump(best_params, f)\n",
    "\n",
    "    optimal_k = best_params[\"k\"]\n",
    "    optimal_reg = best_params[\"lambda_reg\"]\n",
    "    optimal_lr = best_params[\"learning_rate\"]\n",
    "\n",
    "    pop_biases_cornac, metrics_dict_cornac = modelling_mf.train_algorithm_cornac(\n",
    "        algorithm=algorithm_cornac(\n",
    "            k=optimal_k,\n",
    "            use_bias=args[\"bias\"],\n",
    "            lambda_reg=optimal_reg,\n",
    "            learning_rate=optimal_lr,\n",
    "        ),\n",
    "        algo_name=algo_name,\n",
    "        ratings=ratings,\n",
    "        evaluation_way=evaluation_way,\n",
    "        verbose=verbose,\n",
    "        n=nr_recs,\n",
    "        sampling_strategy=sampling_strategy,\n",
    "        partition_way=partition_way,\n",
    "        plot=plot,\n",
    "        data_strategy=data_strategy,\n",
    "        args=args,\n",
    "        save_plot=save_plot,\n",
    "    )\n",
    "\n",
    "    # Save metrics!\n",
    "    with open(\n",
    "        \"experimental_results/\"\n",
    "        + algo_name\n",
    "        + \"/\"\n",
    "        + data_strategy\n",
    "        + \"_\"\n",
    "        + str(args)\n",
    "        + \".pkl\",\n",
    "        \"wb\",\n",
    "    ) as f:\n",
    "        pickle.dump(metrics_dict_cornac, f)\n",
    "    with open('experimental_results/'+algo_name+'/detailed_per_item_'+data_strategy+'_'+str(args)+'.pkl', 'wb') as f:\n",
    "        pickle.dump(pop_biases_cornac, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c3278b04384a1f2d1b0bc3e8783905713abb1db8d84b3b69ddff13fab40f022"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
