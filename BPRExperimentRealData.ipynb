{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc80e674",
   "metadata": {},
   "source": [
    "# Steps\n",
    "1. Choose data scenario.\n",
    "2. Generate the dataset accordingly.\n",
    "3. Analyze the dataset.\n",
    "4. Choose an algorithm to investigate.\n",
    "5. Choose 'fixed' configuration.\n",
    "6. For each 'fixed' configuration, optimize the other parameters based on RMSE.\n",
    "7. Given optimal setting, run popularity bias analysis for every version of the 'fixed' configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d29498",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a31a8e0-4e0b-4306-90c1-9136495b5bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env MKL_THREADING_LAYER=tbb\n",
    "%env OPENBLAS_NUM_THREADS=24\n",
    "%env NUMBA_NUM_THREADS=96\n",
    "%env MKL_NUM_THREADS=96\n",
    "%env OMP_NUM_THREADS=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261f8b85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"tbb\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = '24'\n",
    "os.environ[\"NUMBA_NUM_THREADS\"] = '96'\n",
    "os.environ[\"MKL_NUM_THREADS\"] = '96'\n",
    "os.environ[\"OMP_NUM_THREADS\"] = '1'\n",
    "# for random generation\n",
    "import numpy as np \n",
    "import random as rd\n",
    "\n",
    "\n",
    "# basic functions\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 100\n",
    "import pickle\n",
    "import scipy \n",
    "\n",
    "# custom-made functions\n",
    "import modelling_mf\n",
    "from data_generation import generate_data\n",
    "from optimize_hp import optimize_lkpy, optimize_cornac\n",
    "\n",
    "\n",
    "\n",
    "# cornac RS library\n",
    "from cornac.models import bpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a89599-5004-4b31-ad70-939c012fccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lenskit_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cada525",
   "metadata": {},
   "source": [
    "## Data and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce222894-dbfd-48bd-ba5e-761f2232de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=\"epinion\"\n",
    "mat = scipy.io.loadmat(\"data/\"+data+\"_events.mat\")\n",
    "mat_df = pd.DataFrame(mat['rating_with_timestamp'])\n",
    "mat_df.columns = ['user', 'item', '.', 'rating', '..', '...']\n",
    "epinion_ratings = mat_df[['user','item','rating']].drop_duplicates(subset = ['user','item'], keep = 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93470ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=\"fairbook\"\n",
    "# user-item interactions\n",
    "fairbook_ratings = pd.read_csv(\"data/\"+data+\"_events.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de77bc7a-4ef5-4840-9c51-7a683953f4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=\"ml1m\"\n",
    "# user-item interactions\n",
    "ml1m_ratings = pd.read_csv(\"data/\"+data+\"_events.dat\", header=None, sep='::', engine='python').drop(3, axis=1)\n",
    "ml1m_ratings.columns = ['user', 'item', 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940275c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_col = \"user\" # the name of the column that includes the users\n",
    "item_col = \"item\" # the name of the column that includes the items\n",
    "predict_col=\"rating\" # the name of the column that includes the interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed50835-2957-4f37-9366-42aaf90c8478",
   "metadata": {},
   "source": [
    "Make data choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac728b1-5405-4bd4-923a-c81d007d40cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = epinion_ratings.copy()\n",
    "data_strategy = 'epinion'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e219eda1-c01f-4e60-9dfa-b8a4ad1f3a9c",
   "metadata": {},
   "source": [
    "## Optimize, train, evaluate LKPY\n",
    "- **Algorithm**\n",
    "- **Fixed parameters**\n",
    "- **To-optimize parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bee60f7-aac3-47e8-b59f-7d1606cd54c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_versions = {\"BPR\":[{\"bias\":True},\n",
    "                       ]\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b065681-33c1-45d1-a92f-b20a37304d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_way = \"cross_validation\"\n",
    "verbose = True\n",
    "plot = True\n",
    "save_plot = True # save the plots\n",
    "fallback = False\n",
    "nr_recs = 10\n",
    "sampling_strategy = \"frac\"\n",
    "partition_way = \"user\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33ba85a-f68c-4e34-8578-5532197b173c",
   "metadata": {},
   "source": [
    "Epochs = 50 for epinion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7b8bae-58d3-4cfe-807c-70c101b5549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose algorithm\n",
    "algorithm_lkpy = lenskit_tf.BPR\n",
    "algo_name = \"BPR\"\n",
    "versions = algo_versions[algo_name]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# for every 'fixed' version of the algorithm\n",
    "for args in versions:\n",
    "    print(data_strategy, args)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    p = 'best_parameters/'+algo_name+'/'+data_strategy+'_'+str(args)+'.pkl'\n",
    "    if os.path.isfile(p):\n",
    "        print('We got them already')\n",
    "        with open(p, 'rb') as f:\n",
    "            best_params = pickle.load(f)\n",
    "    else:\n",
    "\n",
    "\n",
    "        print('We have to compute them now')\n",
    "        # optimize for this fixed version\n",
    "        best_params = optimize_lkpy(ratings=ratings, algorithm_name=algo_name, args=args, partition_way=row,max_evals=20)\n",
    "    \n",
    "        # save the best parameters for this fixed version\n",
    "    \n",
    "        with open('best_parameters/'+algo_name+'/'+data_strategy+'_'+str(args)+'.pkl', 'wb') as f:\n",
    "            pickle.dump(best_params, f)\n",
    "\n",
    "    \n",
    "    features_list = [10, 50,100] # check\n",
    "    optimal_features = features_list[best_params[\"features\"]]\n",
    "\n",
    "    reg_list = [0, 0.001, 0.01, 0.1]\n",
    "    optimal_reg = reg_list[best_params[\"reg\"]]\n",
    "\n",
    "\n",
    "    neg_weight_list = [True, False]\n",
    "    optimal_nw = neg_weight_list[best_params[\"neg_weight\"]]\n",
    "\n",
    "\n",
    "    # run the training and evaluation for the fixed version + the best other parameters\n",
    "    pop_biases_lkpy, metrics_dict_lkpy = modelling_mf.train_algorithm(algorithm = algorithm_lkpy(features=optimal_features,\n",
    "                                                                                                 reg=optimal_reg,\n",
    "                                                                                                 neg_weight=optimal_nw,\n",
    "                                                                                                epochs=50,\n",
    "                                                                                                ),\n",
    "                                                    algo_name = algo_name,  \n",
    "                                                    ratings = ratings,\n",
    "                                                    evaluation_way = evaluation_way,\n",
    "                                                    verbose = verbose, \n",
    "                                                    n=nr_recs,\n",
    "                                                    sampling_strategy = sampling_strategy,\n",
    "                                                    partition_way = partition_way,\n",
    "                                                    plot = plot,\n",
    "                                                data_strategy=data_strategy,\n",
    "                                                args=args,\n",
    "                                                save_plot=save_plot)\n",
    "\n",
    "    # Save metrics!\n",
    "    with open('experimental_results/'+algo_name+'/'+data_strategy+'_'+str(args)+'.pkl', 'wb') as f:\n",
    "        pickle.dump(metrics_dict_lkpy, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e535cae7",
   "metadata": {},
   "source": [
    "## Optimize, train, evaluate Cornac\n",
    "- **Algorithm**\n",
    "- **Fixed parameters**\n",
    "- **To-optimize parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d21c337-81a1-4667-9ae0-08419e98c625",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {} # Create a dictionary that maps each item to an integer - necessary for Cornac.\n",
    "i=0\n",
    "for mov in ratings[item_col].unique():\n",
    "    mapping_dict[mov] = i\n",
    "    i+=1\n",
    "ratings[item_col] = ratings[item_col].map(lambda x: mapping_dict.get(x,x)) # Map in the ratings file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b407cd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_versions = {\"CornacBPR\":[{\"bias\":True},\n",
    "                       {\"bias\":False}]\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f94627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_way = \"cross_validation\"\n",
    "verbose = True\n",
    "plot = True\n",
    "save_plot = True # save the plots\n",
    "fallback = False\n",
    "nr_recs = 10\n",
    "sampling_strategy = \"frac\"\n",
    "partition_way = \"user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b31512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose algorithm\n",
    "algorithm_cornac = bpr.BPR\n",
    "algo_name = \"CornacBPR\"\n",
    "versions = algo_versions[algo_name]\n",
    "\n",
    "\n",
    "\n",
    "# for every 'fixed' version of the algorithm\n",
    "for args in versions:\n",
    "    print(data_strategy, args)\n",
    "    \n",
    "    p = 'best_parameters/'+algo_name+'/'+data_strategy+'_'+str(args)+'.pkl'\n",
    "    if os.path.isfile(p):\n",
    "        print('We got them already')\n",
    "        with open(p, 'rb') as f:\n",
    "            best_params = pickle.load(f)\n",
    "    else:\n",
    "\n",
    "\n",
    "        print('We have to compute them now')\n",
    "        # optimize for this fixed version\n",
    "        best_params = optimize_cornac(ratings=ratings, algorithm_name=algo_name, args=args, max_evals=20)\n",
    "    \n",
    "        # save the best parameters for this fixed version\n",
    "    \n",
    "        with open('best_parameters/'+algo_name+'/'+data_strategy+'_'+str(args)+'.pkl', 'wb') as f:\n",
    "            pickle.dump(best_params, f)\n",
    "\n",
    "    \n",
    "    optimal_k = best_params[\"k\"]\n",
    "    optimal_reg = best_params[\"lambda_reg\"]\n",
    "    optimal_lr = best_params[\"learning_rate\"]\n",
    "\n",
    "    \n",
    "\n",
    "    # run the training and evaluation for the fixed version + the best other parameters\n",
    "    pop_biases_cornac, metrics_dict_cornac = modelling_mf.train_algorithm_cornac(algorithm = algorithm_cornac(k=optimal_k,\n",
    "                                                            \n",
    "                                                            lambda_reg=optimal_reg,\n",
    "                                                            learning_rate=optimal_lr,\n",
    "                                                            \n",
    "                                                            use_bias=args['bias']),algo_name = algo_name,  ratings = ratings, evaluation_way = evaluation_way,\n",
    "                                                    verbose = verbose, \n",
    "                                                    n=nr_recs,\n",
    "                                                    sampling_strategy = sampling_strategy,\n",
    "                                                    partition_way = partition_way,\n",
    "                                                    plot = plot,\n",
    "                                                data_strategy=data_strategy,\n",
    "                                                args=args,\n",
    "                                                save_plot=save_plot)\n",
    "\n",
    "    # Save metrics!\n",
    "    with open('experimental_results/'+algo_name+'/'+data_strategy+'_'+str(args)+'.pkl', 'wb') as f:\n",
    "        pickle.dump(metrics_dict_cornac, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c3278b04384a1f2d1b0bc3e8783905713abb1db8d84b3b69ddff13fab40f022"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
