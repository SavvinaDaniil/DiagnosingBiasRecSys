{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc80e674",
   "metadata": {},
   "source": [
    "# Steps\n",
    "1. Make data choice.\n",
    "5. Choose 'fixed' configuration.\n",
    "6. For each 'fixed' configuration, optimize the other parameters based on RMSE.\n",
    "7. Given optimal setting, run popularity bias analysis for every version of the 'fixed' configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d29498",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fddd0f1b-6eed-4726-a32d-7e8828de575b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MKL_THREADING_LAYER=tbb\n",
      "env: OPENBLAS_NUM_THREADS=24\n",
      "env: NUMBA_NUM_THREADS=96\n",
      "env: MKL_NUM_THREADS=96\n",
      "env: OMP_NUM_THREADS=1\n"
     ]
    }
   ],
   "source": [
    "%env MKL_THREADING_LAYER=tbb\n",
    "%env OPENBLAS_NUM_THREADS=24\n",
    "%env NUMBA_NUM_THREADS=96\n",
    "%env MKL_NUM_THREADS=96\n",
    "%env OMP_NUM_THREADS=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "261f8b85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"tbb\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = '24'\n",
    "os.environ[\"NUMBA_NUM_THREADS\"] = '96'\n",
    "os.environ[\"MKL_NUM_THREADS\"] = '96'\n",
    "os.environ[\"OMP_NUM_THREADS\"] = '1'\n",
    "# for random generation\n",
    "import numpy as np \n",
    "import random as rd\n",
    "\n",
    "\n",
    "# basic functions\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 100\n",
    "import pickle\n",
    "import scipy.io\n",
    "\n",
    "\n",
    "# custom-made functions\n",
    "import modelling_mf\n",
    "from optimize_hp import optimize_lkpy, optimize_cornac\n",
    "\n",
    "# lenskit RS library\n",
    "from lenskit.algorithms import user_knn\n",
    "\n",
    "\n",
    "# cornac RS library\n",
    "from cornac.models import UserKNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cada525",
   "metadata": {},
   "source": [
    "## Data and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b59cc8df-330c-4ca4-a363-6447bdb07d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=\"epinion\"\n",
    "mat = scipy.io.loadmat(\"data/\"+data+\"_events.mat\")\n",
    "mat_df = pd.DataFrame(mat['rating_with_timestamp'])\n",
    "mat_df.columns = ['user', 'item', '.', 'rating', '..', '...']\n",
    "epinion_ratings = mat_df[['user','item','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "168e374f-67a7-465a-8cbd-56f8b1f2bed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=\"ml1m\"\n",
    "# user-item interactions\n",
    "ml1m_ratings = pd.read_csv(\"data/\"+data+\"_events.dat\", header=None, sep='::', engine='python').drop(3, axis=1)\n",
    "ml1m_ratings.columns = ['user', 'item', 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d698a0c9-167d-462f-af50-158c8c5c4855",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=\"fairbook\"\n",
    "# user-item interactions\n",
    "fairbook_ratings = pd.read_csv(\"data/\"+data+\"_events.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad2b752-1775-48ec-a004-64312f30e68b",
   "metadata": {},
   "source": [
    "Make data choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76dcb918-7bd6-4ad6-8a18-e6c240eb91c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = epinion_ratings.copy()\n",
    "ratings = ratings.drop_duplicates(subset = ['user','item'], keep = 'last')\n",
    "data_strategy = 'epinion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "940275c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_col = \"user\" # the name of the column that includes the users\n",
    "item_col = \"item\" # the name of the column that includes the items\n",
    "predict_col=\"rating\" # the name of the column that includes the interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3655bbae-e509-4ea7-bb15-3dc8a360d007",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_way = \"cross_validation\"\n",
    "verbose = False\n",
    "plot = True\n",
    "save_plot = True # save the plots\n",
    "fallback = False\n",
    "nr_recs = 10\n",
    "sampling_strategy = \"frac\"\n",
    "partition_way = \"user\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e535cae7",
   "metadata": {},
   "source": [
    "## Optimize, train, evaluate LKPY\n",
    "- **Algorithm**\n",
    "- **Fixed parameters**\n",
    "- **To-optimize parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abd28961-e862-4c9d-9e45-7abbf30fa6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_versions = {\"UserKNN\":[{'min_nbrs':1, 'min_sim':0},\n",
    "                            {'min_nbrs':2, 'min_sim':0},\n",
    "                            # {'min_nbrs':10, 'min_sim':0},\n",
    "                            {'min_nbrs':1, 'min_sim':-1},\n",
    "                            {'min_nbrs':2, 'min_sim':-1},\n",
    "                            # {'min_nbrs':10, 'min_sim':-1}\n",
    "                           ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b31512c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_nbrs': 1, 'min_sim': 0}\n",
      "We got them already\n",
      "nr of longtail 6315\n",
      "1.436533212010919\n",
      "nr of longtail 6629\n",
      "1.509335154826958\n",
      "nr of longtail 6365\n",
      "1.4469197544896568\n",
      "nr of longtail 6509\n",
      "1.4806642402183803\n",
      "nr of longtail 6887\n",
      "1.5698655117392295\n"
     ]
    }
   ],
   "source": [
    "# choose algorithm\n",
    "algorithm_lkpy = user_knn.UserUser\n",
    "algo_name = \"UserKNN\"\n",
    "versions = algo_versions[algo_name]\n",
    "\n",
    "# for every 'fixed' version of the algorithm\n",
    "for args in versions:\n",
    "    print(args)\n",
    "\n",
    "    p = \"best_parameters/\" + algo_name + \"/\" + data_strategy + \"_\" + str(args) + \".pkl\"\n",
    "    if os.path.isfile(p):\n",
    "        print(\"We got them already\")\n",
    "        with open(p, \"rb\") as f:\n",
    "            best_params = pickle.load(f)\n",
    "    else:\n",
    "        print(\"We have to compute them now\")\n",
    "        # optimize for this fixed version\n",
    "        best_params = optimize_lkpy(\n",
    "            ratings=ratings, algorithm_name=algo_name, args=args, max_evals=20, partition_way = 'row'\n",
    "        )\n",
    "\n",
    "        # save the best parameters for this fixed version\n",
    "\n",
    "        with open(\n",
    "            \"best_parameters/\"\n",
    "            + algo_name\n",
    "            + \"/\"\n",
    "            + data_strategy\n",
    "            + \"_\"\n",
    "            + str(args)\n",
    "            + \".pkl\",\n",
    "            \"wb\",\n",
    "        ) as f:\n",
    "            pickle.dump(best_params, f)\n",
    "\n",
    "    \n",
    "    # # optimize for this fixed version\n",
    "    # best_params = optimize_lkpy(ratings=ratings, algorithm_name=algo_name, args=args, partition_way='row', max_evals=20)\n",
    "\n",
    "    # # save the best parameters for this fixed version\n",
    "\n",
    "    # with open('best_parameters/'+algo_name+'/'+data_strategy+'_'+str(args)+'.pkl', 'wb') as f:\n",
    "    #     pickle.dump(best_params, f)\n",
    "\n",
    "\n",
    "    optimal_nnbrs = best_params[\"nnbrs\"]\n",
    "    \n",
    "\n",
    "    # run the training and evaluation for the fixed version + the best other parameters\n",
    "    pop_biases_lkpy, metrics_dict_lkpy = modelling_mf.train_algorithm(algorithm = algorithm_lkpy(nnbrs=optimal_nnbrs,\n",
    "                                                            \n",
    "                                                            center=True,\n",
    "                                                            min_sim=args['min_sim'],\n",
    "                                                            min_nbrs=args['min_nbrs']),\n",
    "                                                    algo_name = algo_name,  \n",
    "                                                    ratings = ratings,\n",
    "                                                    evaluation_way = evaluation_way,\n",
    "                                                    verbose = verbose, \n",
    "                                                    n=nr_recs,\n",
    "                                                    sampling_strategy = sampling_strategy,\n",
    "                                                    partition_way = partition_way,\n",
    "                                                    plot = plot,\n",
    "                                                data_strategy=data_strategy,\n",
    "                                                args=args,\n",
    "                                                save_plot=save_plot)\n",
    "\n",
    "   \n",
    "    # Save metrics!\n",
    "    with open('experimental_results/'+algo_name+'/'+data_strategy+'_'+str(args)+'.pkl', 'wb') as f:\n",
    "        pickle.dump(metrics_dict_lkpy, f)\n",
    "    with open('experimental_results/'+algo_name+'/detailed_per_item_'+data_strategy+'_'+str(args)+'.pkl', 'wb') as f:\n",
    "        pickle.dump(pop_biases_lkpy, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3728de63-aa2c-44a8-961d-8ddee25304f4",
   "metadata": {},
   "source": [
    "## Optimize, train, evaluate Cornac\n",
    "- **Algorithm**\n",
    "- **Fixed parameters**\n",
    "- **To-optimize parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4500c64e-46b6-4e5e-9c5e-a3d3a0fbd4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {} # Create a dictionary that maps each item to an integer - necessary for Cornac.\n",
    "i=0\n",
    "for mov in ratings[item_col].unique():\n",
    "    mapping_dict[mov] = i\n",
    "    i+=1\n",
    "ratings[item_col] = ratings[item_col].map(lambda x: mapping_dict.get(x,x)) # Map in the ratings file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc58b0cf-fa29-4f0f-ae9e-c9d5d886d57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_versions = {\"CornacUserKNN\":[{'center':True}],\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298a412b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epinion {'center': True}\n",
      "We got them already\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3707071013745b69b53043e47a95eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserKNN model is saved to cornacLogs/UserKNN/2024-06-26_17-57-47-597716.pkl\n",
      "\n",
      "TEST:\n",
      "...\n",
      "        |   RMSE | Train (s) | Test (s)\n",
      "------- + ------ + --------- + --------\n",
      "UserKNN | 1.1516 |    7.4706 |   4.2626\n",
      "\n",
      "nr of longtail 16938\n",
      "3.822613405551794\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8bbe78ab5d47f89d439c85d59fec4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserKNN model is saved to cornacLogs/UserKNN/2024-06-26_18-34-41-548967.pkl\n",
      "\n",
      "TEST:\n",
      "...\n",
      "        |   RMSE | Train (s) | Test (s)\n",
      "------- + ------ + --------- + --------\n",
      "UserKNN | 1.1491 |    7.4888 |   4.2403\n",
      "\n"
     ]
    }
   ],
   "source": [
    "algorithm_cornac = UserKNN\n",
    "algo_name = \"CornacUserKNN\"\n",
    "versions = algo_versions[algo_name]\n",
    "\n",
    "for args in versions:\n",
    "    print(data_strategy, args)\n",
    "\n",
    "\n",
    "    p = \"best_parameters/\" + algo_name + \"/\" + data_strategy + \"_\" + str(args) + \".pkl\"\n",
    "    if os.path.isfile(p):\n",
    "        print(\"We got them already\")\n",
    "        with open(p, \"rb\") as f:\n",
    "            best_params = pickle.load(f)\n",
    "    else:\n",
    "        print(\"We have to compute them now\")\n",
    "        # optimize for this fixed version\n",
    "        best_params = optimize_cornac(\n",
    "            ratings=ratings, algorithm_name=algo_name, args=args, max_evals=20\n",
    "        )\n",
    "\n",
    "        # save the best parameters for this fixed version\n",
    "\n",
    "        with open(\n",
    "            \"best_parameters/\"\n",
    "            + algo_name\n",
    "            + \"/\"\n",
    "            + data_strategy\n",
    "            + \"_\"\n",
    "            + str(args)\n",
    "            + \".pkl\",\n",
    "            \"wb\",\n",
    "        ) as f:\n",
    "            pickle.dump(best_params, f)\n",
    "    \n",
    "    # # optimize for this fixed version\n",
    "    # best_params = optimize_cornac(ratings=ratings, algorithm_name=algo_name, args=args, max_evals=20)\n",
    "\n",
    "    # # save the best parameters for this fixed version\n",
    "\n",
    "    # with open('best_parameters/'+algo_name+'/'+data_strategy+'_'+str(args)+'.pkl', 'wb') as f:\n",
    "    #     pickle.dump(best_params, f)\n",
    "\n",
    "\n",
    "    optimal_k = best_params['k']\n",
    "\n",
    "    \n",
    "\n",
    "    pop_biases_cornac, metrics_dict_cornac = modelling_mf.train_algorithm_cornac(algorithm = algorithm_cornac(k=optimal_k,\n",
    "                                                                                                             mean_centered=args['center']),\n",
    "                                                    algo_name = algo_name,  \n",
    "                                                    ratings = ratings,\n",
    "                                                    evaluation_way = evaluation_way,\n",
    "                                                    verbose = verbose, \n",
    "                                                    n=nr_recs,\n",
    "                                                    sampling_strategy = sampling_strategy,\n",
    "                                                    partition_way = partition_way,\n",
    "                                                    plot = plot,\n",
    "                                                data_strategy=data_strategy,\n",
    "                                                args=args,\n",
    "                                                save_plot=save_plot)\n",
    "\n",
    "    # Save metrics!\n",
    "    with open('experimental_results/'+algo_name+'/'+data_strategy+'_'+str(args)+'.pkl', 'wb') as f:\n",
    "        pickle.dump(metrics_dict_cornac, f)\n",
    "    with open('experimental_results/'+algo_name+'/detailed_per_item_'+data_strategy+'_'+str(args)+'.pkl', 'wb') as f:\n",
    "        pickle.dump(pop_biases_cornac, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c3278b04384a1f2d1b0bc3e8783905713abb1db8d84b3b69ddff13fab40f022"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1d0124f3b40f4f52bd03455e7782a5cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_3a096f8ff3084a0db4025febfe842872",
       "max": 22164,
       "style": "IPY_MODEL_eef9664aec564a64ab27d50f93f561e5",
       "value": 22164
      }
     },
     "224016d6b2884f65a3ac21b1642f0d0f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2653ad06db8549cc9c4d4c69fa8048f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3a096f8ff3084a0db4025febfe842872": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3cc5951a54f94aa79bf4870a71ae3b4b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_867e638b6eb0428d86d6ca5c029cae87",
       "max": 22164,
       "style": "IPY_MODEL_f599d67d567f447293ce988731d42460",
       "value": 22164
      }
     },
     "5e5191d2121e40c98986951e77541041": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6be2029216084fa4b9bb1b71db7171d8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6fef7ce6c95648fe88a2865e3773be5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "867e638b6eb0428d86d6ca5c029cae87": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8f65281f1bb449b8b9ca44488d0a9769": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_2653ad06db8549cc9c4d4c69fa8048f5",
       "style": "IPY_MODEL_acf48f8de1bc4d71bb7fba33a9b8f22a",
       "value": "100%"
      }
     },
     "8f8bbe78ab5d47f89d439c85d59fec4f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_8f65281f1bb449b8b9ca44488d0a9769",
        "IPY_MODEL_1d0124f3b40f4f52bd03455e7782a5cf",
        "IPY_MODEL_caa23ae9b7a14023b888c1a50b6dd245"
       ],
       "layout": "IPY_MODEL_aa293ea82b8b4c7e8a424da8ee04cce8"
      }
     },
     "a2640198a1164096b37233eecc2e6bdd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "aa293ea82b8b4c7e8a424da8ee04cce8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "acf48f8de1bc4d71bb7fba33a9b8f22a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b3707071013745b69b53043e47a95eed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_d8331ffc5fd24edfab5bfa931706edc4",
        "IPY_MODEL_3cc5951a54f94aa79bf4870a71ae3b4b",
        "IPY_MODEL_d1e7fbb319604b73be164ae7785add00"
       ],
       "layout": "IPY_MODEL_feb32d934e9145ee9bb0a2295c000531"
      }
     },
     "caa23ae9b7a14023b888c1a50b6dd245": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_dc685b3ce37947e6bf8329afced14a4c",
       "style": "IPY_MODEL_6fef7ce6c95648fe88a2865e3773be5c",
       "value": " 22164/22164 [00:01&lt;00:00, 10215.88it/s]"
      }
     },
     "d1e7fbb319604b73be164ae7785add00": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_6be2029216084fa4b9bb1b71db7171d8",
       "style": "IPY_MODEL_a2640198a1164096b37233eecc2e6bdd",
       "value": " 22164/22164 [00:01&lt;00:00, 1160.69it/s]"
      }
     },
     "d8331ffc5fd24edfab5bfa931706edc4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_5e5191d2121e40c98986951e77541041",
       "style": "IPY_MODEL_224016d6b2884f65a3ac21b1642f0d0f",
       "value": "100%"
      }
     },
     "dc685b3ce37947e6bf8329afced14a4c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "eef9664aec564a64ab27d50f93f561e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f599d67d567f447293ce988731d42460": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "feb32d934e9145ee9bb0a2295c000531": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
