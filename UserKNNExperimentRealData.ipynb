{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc80e674",
   "metadata": {},
   "source": [
    "# Steps\n",
    "1. Make data choice.\n",
    "5. Choose 'fixed' configuration.\n",
    "6. For each 'fixed' configuration, optimize the other parameters based on RMSE.\n",
    "7. Given optimal setting, run popularity bias analysis for every version of the 'fixed' configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d29498",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fddd0f1b-6eed-4726-a32d-7e8828de575b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MKL_THREADING_LAYER=tbb\n",
      "env: OPENBLAS_NUM_THREADS=24\n",
      "env: NUMBA_NUM_THREADS=96\n",
      "env: MKL_NUM_THREADS=96\n",
      "env: OMP_NUM_THREADS=1\n"
     ]
    }
   ],
   "source": [
    "%env MKL_THREADING_LAYER=tbb\n",
    "%env OPENBLAS_NUM_THREADS=24\n",
    "%env NUMBA_NUM_THREADS=96\n",
    "%env MKL_NUM_THREADS=96\n",
    "%env OMP_NUM_THREADS=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "261f8b85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"tbb\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = '24'\n",
    "os.environ[\"NUMBA_NUM_THREADS\"] = '96'\n",
    "os.environ[\"MKL_NUM_THREADS\"] = '96'\n",
    "os.environ[\"OMP_NUM_THREADS\"] = '1'\n",
    "# for random generation\n",
    "import numpy as np \n",
    "import random as rd\n",
    "\n",
    "\n",
    "# basic functions\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 100\n",
    "import pickle\n",
    "import scipy.io\n",
    "\n",
    "\n",
    "# custom-made functions\n",
    "import modelling_mf\n",
    "from optimize_hp import optimize_lkpy, optimize_cornac\n",
    "\n",
    "# lenskit RS library\n",
    "from lenskit.algorithms import user_knn\n",
    "\n",
    "\n",
    "# cornac RS library\n",
    "from cornac.models import UserKNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cada525",
   "metadata": {},
   "source": [
    "## Data and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b59cc8df-330c-4ca4-a363-6447bdb07d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=\"epinion\"\n",
    "mat = scipy.io.loadmat(\"data/\"+data+\"_events.mat\")\n",
    "mat_df = pd.DataFrame(mat['rating_with_timestamp'])\n",
    "mat_df.columns = ['user', 'item', '.', 'rating', '..', '...']\n",
    "epinion_ratings = mat_df[['user','item','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "168e374f-67a7-465a-8cbd-56f8b1f2bed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=\"ml1m\"\n",
    "# user-item interactions\n",
    "ml1m_ratings = pd.read_csv(\"data/\"+data+\"_events.dat\", header=None, sep='::', engine='python').drop(3, axis=1)\n",
    "ml1m_ratings.columns = ['user', 'item', 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d698a0c9-167d-462f-af50-158c8c5c4855",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=\"fairbook\"\n",
    "# user-item interactions\n",
    "fairbook_ratings = pd.read_csv(\"data/\"+data+\"_events.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad2b752-1775-48ec-a004-64312f30e68b",
   "metadata": {},
   "source": [
    "Make data choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76dcb918-7bd6-4ad6-8a18-e6c240eb91c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = epinion_ratings.copy()\n",
    "ratings = ratings.drop_duplicates(subset = ['user','item'], keep = 'last')\n",
    "data_strategy = 'epinion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "940275c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_col = \"user\" # the name of the column that includes the users\n",
    "item_col = \"item\" # the name of the column that includes the items\n",
    "predict_col=\"rating\" # the name of the column that includes the interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3655bbae-e509-4ea7-bb15-3dc8a360d007",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_way = \"cross_validation\"\n",
    "verbose = False\n",
    "plot = True\n",
    "save_plot = True # save the plots\n",
    "fallback = False\n",
    "nr_recs = 10\n",
    "sampling_strategy = \"frac\"\n",
    "partition_way = \"user\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e535cae7",
   "metadata": {},
   "source": [
    "## Optimize, train, evaluate LKPY\n",
    "- **Algorithm**\n",
    "- **Fixed parameters**\n",
    "- **To-optimize parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abd28961-e862-4c9d-9e45-7abbf30fa6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_versions = {\"UserKNN\":[{'min_nbrs':1, 'min_sim':0},\n",
    "                            {'min_nbrs':2, 'min_sim':0},\n",
    "                            # {'min_nbrs':10, 'min_sim':0},\n",
    "                            {'min_nbrs':1, 'min_sim':-1},\n",
    "                            {'min_nbrs':2, 'min_sim':-1},\n",
    "                            # {'min_nbrs':10, 'min_sim':-1}\n",
    "                           ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b31512c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_nbrs': 1, 'min_sim': 0}\n",
      "We got them already\n",
      "nr of longtail 6315\n",
      "1.436533212010919\n",
      "nr of longtail 6629\n",
      "1.509335154826958\n"
     ]
    }
   ],
   "source": [
    "# choose algorithm\n",
    "algorithm_lkpy = user_knn.UserUser\n",
    "algo_name = \"UserKNN\"\n",
    "versions = algo_versions[algo_name]\n",
    "\n",
    "# for every 'fixed' version of the algorithm\n",
    "for args in versions:\n",
    "    print(args)\n",
    "\n",
    "    p = \"best_parameters/\" + algo_name + \"/\" + data_strategy + \"_\" + str(args) + \".pkl\"\n",
    "    if os.path.isfile(p):\n",
    "        print(\"We got them already\")\n",
    "        with open(p, \"rb\") as f:\n",
    "            best_params = pickle.load(f)\n",
    "    else:\n",
    "        print(\"We have to compute them now\")\n",
    "        # optimize for this fixed version\n",
    "        best_params = optimize_lkpy(\n",
    "            ratings=ratings, algorithm_name=algo_name, args=args, max_evals=20, partition_way = 'row'\n",
    "        )\n",
    "\n",
    "        # save the best parameters for this fixed version\n",
    "\n",
    "        with open(\n",
    "            \"best_parameters/\"\n",
    "            + algo_name\n",
    "            + \"/\"\n",
    "            + data_strategy\n",
    "            + \"_\"\n",
    "            + str(args)\n",
    "            + \".pkl\",\n",
    "            \"wb\",\n",
    "        ) as f:\n",
    "            pickle.dump(best_params, f)\n",
    "\n",
    "    \n",
    "    # # optimize for this fixed version\n",
    "    # best_params = optimize_lkpy(ratings=ratings, algorithm_name=algo_name, args=args, partition_way='row', max_evals=20)\n",
    "\n",
    "    # # save the best parameters for this fixed version\n",
    "\n",
    "    # with open('best_parameters/'+algo_name+'/'+data_strategy+'_'+str(args)+'.pkl', 'wb') as f:\n",
    "    #     pickle.dump(best_params, f)\n",
    "\n",
    "\n",
    "    optimal_nnbrs = best_params[\"nnbrs\"]\n",
    "    \n",
    "\n",
    "    # run the training and evaluation for the fixed version + the best other parameters\n",
    "    pop_biases_lkpy, metrics_dict_lkpy = modelling_mf.train_algorithm(algorithm = lambda: algorithm_lkpy(nnbrs=optimal_nnbrs,\n",
    "                                                            \n",
    "                                                            center=True,\n",
    "                                                            min_sim=args['min_sim'],\n",
    "                                                            min_nbrs=args['min_nbrs']),\n",
    "                                                    algo_name = algo_name,  \n",
    "                                                    ratings = ratings,\n",
    "                                                    evaluation_way = evaluation_way,\n",
    "                                                    verbose = verbose, \n",
    "                                                    n=nr_recs,\n",
    "                                                    sampling_strategy = sampling_strategy,\n",
    "                                                    partition_way = partition_way,\n",
    "                                                    plot = plot,\n",
    "                                                data_strategy=data_strategy,\n",
    "                                                args=args,\n",
    "                                                save_plot=save_plot)\n",
    "\n",
    "   \n",
    "    # Save metrics!\n",
    "    with open('experimental_results/'+algo_name+'/'+data_strategy+'_'+str(args)+'.pkl', 'wb') as f:\n",
    "        pickle.dump(metrics_dict_lkpy, f)\n",
    "    with open('experimental_results/'+algo_name+'/detailed_per_item_'+data_strategy+'_'+str(args)+'.pkl', 'wb') as f:\n",
    "        pickle.dump(pop_biases_lkpy, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3728de63-aa2c-44a8-961d-8ddee25304f4",
   "metadata": {},
   "source": [
    "## Optimize, train, evaluate Cornac\n",
    "- **Algorithm**\n",
    "- **Fixed parameters**\n",
    "- **To-optimize parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4500c64e-46b6-4e5e-9c5e-a3d3a0fbd4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {} # Create a dictionary that maps each item to an integer - necessary for Cornac.\n",
    "i=0\n",
    "for mov in ratings[item_col].unique():\n",
    "    mapping_dict[mov] = i\n",
    "    i+=1\n",
    "ratings[item_col] = ratings[item_col].map(lambda x: mapping_dict.get(x,x)) # Map in the ratings file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc58b0cf-fa29-4f0f-ae9e-c9d5d886d57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_versions = {\"CornacUserKNN\":[{'center':True}],\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298a412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_cornac = UserKNN\n",
    "algo_name = \"CornacUserKNN\"\n",
    "versions = algo_versions[algo_name]\n",
    "\n",
    "for args in versions:\n",
    "    print(data_strategy, args)\n",
    "\n",
    "\n",
    "    p = \"best_parameters/\" + algo_name + \"/\" + data_strategy + \"_\" + str(args) + \".pkl\"\n",
    "    if os.path.isfile(p):\n",
    "        print(\"We got them already\")\n",
    "        with open(p, \"rb\") as f:\n",
    "            best_params = pickle.load(f)\n",
    "    else:\n",
    "        print(\"We have to compute them now\")\n",
    "        # optimize for this fixed version\n",
    "        best_params = optimize_cornac(\n",
    "            ratings=ratings, algorithm_name=algo_name, args=args, max_evals=20\n",
    "        )\n",
    "\n",
    "        # save the best parameters for this fixed version\n",
    "\n",
    "        with open(\n",
    "            \"best_parameters/\"\n",
    "            + algo_name\n",
    "            + \"/\"\n",
    "            + data_strategy\n",
    "            + \"_\"\n",
    "            + str(args)\n",
    "            + \".pkl\",\n",
    "            \"wb\",\n",
    "        ) as f:\n",
    "            pickle.dump(best_params, f)\n",
    "    \n",
    "    # # optimize for this fixed version\n",
    "    # best_params = optimize_cornac(ratings=ratings, algorithm_name=algo_name, args=args, max_evals=20)\n",
    "\n",
    "    # # save the best parameters for this fixed version\n",
    "\n",
    "    # with open('best_parameters/'+algo_name+'/'+data_strategy+'_'+str(args)+'.pkl', 'wb') as f:\n",
    "    #     pickle.dump(best_params, f)\n",
    "\n",
    "\n",
    "    optimal_k = best_params['k']\n",
    "\n",
    "    \n",
    "\n",
    "    pop_biases_cornac, metrics_dict_cornac = modelling_mf.train_algorithm_cornac(algorithm = lambda: algorithm_cornac(k=optimal_k,\n",
    "                                                                                                             mean_centered=args['center']),\n",
    "                                                    algo_name = algo_name,  \n",
    "                                                    ratings = ratings,\n",
    "                                                    evaluation_way = evaluation_way,\n",
    "                                                    verbose = verbose, \n",
    "                                                    n=nr_recs,\n",
    "                                                    sampling_strategy = sampling_strategy,\n",
    "                                                    partition_way = partition_way,\n",
    "                                                    plot = plot,\n",
    "                                                data_strategy=data_strategy,\n",
    "                                                args=args,\n",
    "                                                save_plot=save_plot)\n",
    "\n",
    "    # Save metrics!\n",
    "    with open('experimental_results/'+algo_name+'/'+data_strategy+'_'+str(args)+'.pkl', 'wb') as f:\n",
    "        pickle.dump(metrics_dict_cornac, f)\n",
    "    with open('experimental_results/'+algo_name+'/detailed_per_item_'+data_strategy+'_'+str(args)+'.pkl', 'wb') as f:\n",
    "        pickle.dump(pop_biases_cornac, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c3278b04384a1f2d1b0bc3e8783905713abb1db8d84b3b69ddff13fab40f022"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
