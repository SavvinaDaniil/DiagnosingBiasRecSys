{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc80e674",
   "metadata": {},
   "source": [
    "# Steps\n",
    "1. Make data choice.\n",
    "5. Choose 'fixed' configuration.\n",
    "6. For each 'fixed' configuration, optimize the other parameters based on RMSE.\n",
    "7. Given optimal setting, run popularity bias analysis for every version of the 'fixed' configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d29498",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d87f4ad4-cce3-418c-b189-324f9b6a7197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MKL_THREADING_LAYER=tbb\n",
      "env: OPENBLAS_NUM_THREADS=24\n",
      "env: NUMBA_NUM_THREADS=96\n",
      "env: MKL_NUM_THREADS=96\n",
      "env: OMP_NUM_THREADS=1\n"
     ]
    }
   ],
   "source": [
    "%env MKL_THREADING_LAYER=tbb\n",
    "%env OPENBLAS_NUM_THREADS=24\n",
    "%env NUMBA_NUM_THREADS=96\n",
    "%env MKL_NUM_THREADS=96\n",
    "%env OMP_NUM_THREADS=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "261f8b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"tbb\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"24\"\n",
    "os.environ[\"NUMBA_NUM_THREADS\"] = \"96\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"96\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "# for random generation\n",
    "\n",
    "\n",
    "# basic functions\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_rows = 100\n",
    "import pickle\n",
    "import scipy\n",
    "\n",
    "# custom-made functions\n",
    "import modelling_mf\n",
    "from optimize_hp import optimize_lkpy, optimize_cornac\n",
    "\n",
    "# lenskit RS library\n",
    "from lenskit.algorithms import als\n",
    "\n",
    "\n",
    "# cornac RS library\n",
    "from cornac.models import MF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cada525",
   "metadata": {},
   "source": [
    "## Data and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b93470ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"fairbook\"\n",
    "# user-item interactions\n",
    "fairbook_ratings = pd.read_csv(\"data/\" + data + \"_events.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53c071e3-8f6a-45af-b044-e3ca966e2222",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"ml1m\"\n",
    "# user-item interactions\n",
    "ml1m_ratings = pd.read_csv(\n",
    "    \"data/\" + data + \"_events.dat\", header=None, sep=\"::\", engine=\"python\"\n",
    ").drop(3, axis=1)\n",
    "ml1m_ratings.columns = [\"user\", \"item\", \"rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89248693-6210-4bbb-907d-af76e8da7111",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"epinion\"\n",
    "mat = scipy.io.loadmat(\"data/\" + data + \"_events.mat\")\n",
    "mat_df = pd.DataFrame(mat[\"rating_with_timestamp\"])\n",
    "mat_df.columns = [\"user\", \"item\", \".\", \"rating\", \"..\", \"...\"]\n",
    "epinion_ratings = mat_df[[\"user\", \"item\", \"rating\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8685e42b-e5ec-4032-9045-9549de9f64b5",
   "metadata": {},
   "source": [
    "Make data choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3885594-8ab9-4f0b-aa66-322bfe86e633",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ml1m_ratings.copy()\n",
    "ratings = ratings.drop_duplicates(subset=[\"user\", \"item\"], keep=\"last\")\n",
    "data_strategy = \"ml1m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "940275c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_col = \"user\"  # the name of the column that includes the users\n",
    "item_col = \"item\"  # the name of the column that includes the items\n",
    "predict_col = \"rating\"  # the name of the column that includes the interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d390e90-3c0b-4678-bae1-8a6438b55eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_way = \"cross_validation\"\n",
    "verbose = True\n",
    "plot = True\n",
    "save_plot = True  # save the plots\n",
    "fallback = False\n",
    "nr_recs = 10\n",
    "sampling_strategy = \"frac\"\n",
    "partition_way = \"user\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e535cae7",
   "metadata": {},
   "source": [
    "## Optimize, train, evaluate LKPY\n",
    "- **Algorithm**\n",
    "- **Fixed parameters**\n",
    "- **To-optimize parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b407cd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_versions = {\"MF\": [{\"bias\": True}, {\"bias\": False}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b31512c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bias': True}\n",
      "We got them already\n",
      "0 Training done!\n",
      "Prediction done!\n",
      "0 Recommendation done!\n",
      "nr of longtail 943\n",
      "0.21281877679981945\n",
      "1 Training done!\n",
      "Prediction done!\n",
      "1 Recommendation done!\n",
      "nr of longtail 939\n",
      "0.21186823104693142\n",
      "2 Training done!\n",
      "Prediction done!\n",
      "2 Recommendation done!\n",
      "nr of longtail 967\n",
      "0.21818592057761732\n",
      "3 Training done!\n",
      "Prediction done!\n",
      "3 Recommendation done!\n",
      "nr of longtail 885\n",
      "0.1997291807718348\n",
      "4 Training done!\n",
      "Prediction done!\n",
      "4 Recommendation done!\n",
      "nr of longtail 964\n",
      "0.21755811329271044\n"
     ]
    }
   ],
   "source": [
    "# choose algorithm\n",
    "algorithm_lkpy = als.BiasedMF\n",
    "algo_name = \"MF\"\n",
    "versions = algo_versions[algo_name]\n",
    "\n",
    "\n",
    "# for every 'fixed' version of the algorithm\n",
    "for args in versions:\n",
    "    print(args)\n",
    "\n",
    "\n",
    "    p = \"best_parameters/\" + algo_name + \"/\" + data_strategy + \"_\" + str(args) + \".pkl\"\n",
    "    if os.path.isfile(p):\n",
    "        print(\"We got them already\")\n",
    "        with open(p, \"rb\") as f:\n",
    "            best_params = pickle.load(f)\n",
    "    else:\n",
    "        print(\"We have to compute them now\")\n",
    "        # optimize for this fixed version\n",
    "        best_params = optimize_lkpy(\n",
    "            ratings=ratings, algorithm_name=algo_name, args=args, max_evals=20, partition_way = 'row'\n",
    "        )\n",
    "\n",
    "        # save the best parameters for this fixed version\n",
    "\n",
    "        with open(\n",
    "            \"best_parameters/\"\n",
    "            + algo_name\n",
    "            + \"/\"\n",
    "            + data_strategy\n",
    "            + \"_\"\n",
    "            + str(args)\n",
    "            + \".pkl\",\n",
    "            \"wb\",\n",
    "        ) as f:\n",
    "            pickle.dump(best_params, f)\n",
    "    \n",
    "    # # optimize for this fixed version\n",
    "    # best_params = optimize_lkpy(\n",
    "    #     ratings=ratings,\n",
    "    #     algorithm_name=algo_name,\n",
    "    #     args=args,\n",
    "    #     partition_way=\"row\",\n",
    "    #     max_evals=20,\n",
    "    # )\n",
    "\n",
    "    # # save the best parameters for this fixed version\n",
    "\n",
    "    # with open(\n",
    "    #     \"best_parameters/\" + algo_name + \"/\" + data_strategy + \"_\" + str(args) + \".pkl\",\n",
    "    #     \"wb\",\n",
    "    # ) as f:\n",
    "    #     pickle.dump(best_params, f)\n",
    "\n",
    "    reg_list = [0, 0.001, 0.01, 0.1]\n",
    "    features_list = [10, 50, 100]\n",
    "    optimal_reg = reg_list[best_params[\"reg\"]]\n",
    "    optimal_features = features_list[best_params[\"features\"]]\n",
    "\n",
    "    # run the training and evaluation for the fixed version + the best other parameters\n",
    "    pop_biases_lkpy, metrics_dict_lkpy = modelling_mf.train_algorithm(\n",
    "        algorithm=algorithm_lkpy(\n",
    "            features=optimal_features, reg=optimal_reg, bias=args[\"bias\"]\n",
    "        ),\n",
    "        algo_name=algo_name,\n",
    "        ratings=ratings,\n",
    "        evaluation_way=evaluation_way,\n",
    "        verbose=verbose,\n",
    "        n=nr_recs,\n",
    "        sampling_strategy=sampling_strategy,\n",
    "        partition_way=partition_way,\n",
    "        plot=plot,\n",
    "        data_strategy=data_strategy,\n",
    "        args=args,\n",
    "        save_plot=save_plot,\n",
    "    )\n",
    "\n",
    "    # Save metrics!\n",
    "    with open(\n",
    "        \"experimental_results/\"\n",
    "        + algo_name\n",
    "        + \"/\"\n",
    "        + data_strategy\n",
    "        + \"_\"\n",
    "        + str(args)\n",
    "        + \".pkl\",\n",
    "        \"wb\",\n",
    "    ) as f:\n",
    "        pickle.dump(metrics_dict_lkpy, f)\n",
    "    with open('experimental_results/'+algo_name+'/detailed_per_item_'+data_strategy+'_'+str(args)+'.pkl', 'wb') as f:\n",
    "        pickle.dump(pop_biases_lkpy, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12c2a15-73df-4d93-885d-bf76084714f2",
   "metadata": {},
   "source": [
    "## Optimize, train, evaluate Cornac\n",
    "- **Algorithm**\n",
    "- **Fixed parameters**\n",
    "- **To-optimize parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "182fa673-122f-40df-a9e9-32f940f51e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {}  # Create a dictionary that maps each item to an integer - necessary for Cornac.\n",
    "i = 0\n",
    "for mov in ratings[item_col].unique():\n",
    "    mapping_dict[mov] = i\n",
    "    i += 1\n",
    "ratings[item_col] = ratings[item_col].map(\n",
    "    lambda x: mapping_dict.get(x, x)\n",
    ")  # Map in the ratings file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ca6a8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_versions = {\"CornacMF\": [{\"bias\": True}, {\"bias\": False}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bba024d-1f1e-4b33-981c-32d443eec2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml1m {'bias': True}\n",
      "We got them already\n",
      "\n",
      "[MF] Training started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a05daaf43450410aaf9419530a40dcbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization finished!\n",
      "\n",
      "[MF] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0b73dafc704acfaf365ee80f313f76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rating:   0%|          | 0/39278 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'is_unk_user'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m optimal_reg \u001b[38;5;241m=\u001b[39m best_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlambda_reg\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     38\u001b[0m optimal_lr \u001b[38;5;241m=\u001b[39m best_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 40\u001b[0m pop_biases_cornac, metrics_dict_cornac \u001b[38;5;241m=\u001b[39m \u001b[43mmodelling_mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_algorithm_cornac\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgorithm_cornac\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimal_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlambda_reg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimal_reg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimal_lr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mratings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mratings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluation_way\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluation_way\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnr_recs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampling_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartition_way\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_way\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_plot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_plot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Save metrics!\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperimental_results/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;241m+\u001b[39m algo_name\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     70\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/new_environment/DiagnosingBiasRecSys/modelling_mf.py:491\u001b[0m, in \u001b[0;36mtrain_algorithm_cornac\u001b[0;34m(algorithm, algo_name, ratings, evaluation_way, partition_way, sampling_strategy, verbose, min_sim, user_col, item_col, predict_col, n, plot, args, data_strategy, save_plot)\u001b[0m\n\u001b[1;32m    482\u001b[0m metrics \u001b[38;5;241m=\u001b[39m [RMSE()]\n\u001b[1;32m    483\u001b[0m exp \u001b[38;5;241m=\u001b[39m cornac\u001b[38;5;241m.\u001b[39mExperiment(\n\u001b[1;32m    484\u001b[0m     eval_method\u001b[38;5;241m=\u001b[39meval_method,\n\u001b[1;32m    485\u001b[0m     models\u001b[38;5;241m=\u001b[39mmodels,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    489\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    490\u001b[0m )\n\u001b[0;32m--> 491\u001b[0m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m loss \u001b[38;5;241m=\u001b[39m exp\u001b[38;5;241m.\u001b[39mresult[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmetric_avg_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    493\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n",
      "File \u001b[0;32m~/new_environment/conda/envs/biasenv_1.18cornac/lib/python3.8/site-packages/cornac/experiment/experiment.py:142\u001b[0m, in \u001b[0;36mExperiment.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m         model\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels:\n\u001b[0;32m--> 142\u001b[0m     test_result, val_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_method\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_based\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_based\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult\u001b[38;5;241m.\u001b[39mappend(test_result)\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/new_environment/conda/envs/biasenv_1.18cornac/lib/python3.8/site-packages/cornac/eval_methods/base_method.py:747\u001b[0m, in \u001b[0;36mBaseMethod.evaluate\u001b[0;34m(self, model, metrics, user_based, show_validation)\u001b[0m\n\u001b[1;32m    745\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    746\u001b[0m model\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_set)\n\u001b[0;32m--> 747\u001b[0m test_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrating_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrating_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude_unknowns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexclude_unknowns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrating_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrating_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mranking_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mranking_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_based\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_based\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    759\u001b[0m test_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start\n\u001b[1;32m    760\u001b[0m test_result\u001b[38;5;241m.\u001b[39mmetric_avg_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain (s)\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m train_time\n",
      "File \u001b[0;32m~/new_environment/conda/envs/biasenv_1.18cornac/lib/python3.8/site-packages/cornac/eval_methods/base_method.py:671\u001b[0m, in \u001b[0;36mBaseMethod.eval\u001b[0;34m(model, train_set, test_set, val_set, rating_threshold, exclude_unknowns, user_based, rating_metrics, ranking_metrics, verbose)\u001b[0m\n\u001b[1;32m    668\u001b[0m metric_avg_results \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m    669\u001b[0m metric_user_results \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[0;32m--> 671\u001b[0m avg_results, user_results \u001b[38;5;241m=\u001b[39m \u001b[43mrating_eval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrating_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_based\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_based\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, mt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(rating_metrics):\n\u001b[1;32m    679\u001b[0m     metric_avg_results[mt\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m avg_results[i]\n",
      "File \u001b[0;32m~/new_environment/conda/envs/biasenv_1.18cornac/lib/python3.8/site-packages/cornac/eval_methods/base_method.py:71\u001b[0m, in \u001b[0;36mrating_eval\u001b[0;34m(model, metrics, test_set, user_based, verbose)\u001b[0m\n\u001b[1;32m     68\u001b[0m user_results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     70\u001b[0m (u_indices, i_indices, r_values) \u001b[38;5;241m=\u001b[39m test_set\u001b[38;5;241m.\u001b[39muir_tuple\n\u001b[0;32m---> 71\u001b[0m r_preds \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromiter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrate\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muser_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mu_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRating\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mminiters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mu_indices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfloat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m gt_mat \u001b[38;5;241m=\u001b[39m test_set\u001b[38;5;241m.\u001b[39mcsr_matrix\n\u001b[1;32m     86\u001b[0m pd_mat \u001b[38;5;241m=\u001b[39m csr_matrix((r_preds, (u_indices, i_indices)), shape\u001b[38;5;241m=\u001b[39mgt_mat\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/new_environment/conda/envs/biasenv_1.18cornac/lib/python3.8/site-packages/tqdm/notebook.py:249\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/new_environment/conda/envs/biasenv_1.18cornac/lib/python3.8/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/new_environment/conda/envs/biasenv_1.18cornac/lib/python3.8/site-packages/cornac/eval_methods/base_method.py:74\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     68\u001b[0m user_results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     70\u001b[0m (u_indices, i_indices, r_values) \u001b[38;5;241m=\u001b[39m test_set\u001b[38;5;241m.\u001b[39muir_tuple\n\u001b[1;32m     71\u001b[0m r_preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfromiter(\n\u001b[1;32m     72\u001b[0m     tqdm(\n\u001b[1;32m     73\u001b[0m         (\n\u001b[0;32m---> 74\u001b[0m             \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrate\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     75\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m user_idx, item_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(u_indices, i_indices)\n\u001b[1;32m     76\u001b[0m         ),\n\u001b[1;32m     77\u001b[0m         desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRating\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     78\u001b[0m         disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m verbose,\n\u001b[1;32m     79\u001b[0m         miniters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     80\u001b[0m         total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(u_indices),\n\u001b[1;32m     81\u001b[0m     ),\n\u001b[1;32m     82\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     83\u001b[0m )\n\u001b[1;32m     85\u001b[0m gt_mat \u001b[38;5;241m=\u001b[39m test_set\u001b[38;5;241m.\u001b[39mcsr_matrix\n\u001b[1;32m     86\u001b[0m pd_mat \u001b[38;5;241m=\u001b[39m csr_matrix((r_preds, (u_indices, i_indices)), shape\u001b[38;5;241m=\u001b[39mgt_mat\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/new_environment/conda/envs/biasenv_1.18cornac/lib/python3.8/site-packages/cornac/models/recommender.py:451\u001b[0m, in \u001b[0;36mRecommender.rate\u001b[0;34m(self, user_idx, item_idx, clipping)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Give a rating score between pair of user and item\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \n\u001b[1;32m    434\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m    A rating score of the user for the item\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 451\u001b[0m     rating_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ScoreException:\n\u001b[1;32m    453\u001b[0m     rating_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_score()\n",
      "File \u001b[0;32mcornac/models/mf/recom_mf.pyx:255\u001b[0m, in \u001b[0;36mcornac.models.mf.recom_mf.MF.score\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'is_unk_user'"
     ]
    }
   ],
   "source": [
    "algorithm_cornac = MF\n",
    "algo_name = \"CornacMF\"\n",
    "versions = algo_versions[algo_name]\n",
    "\n",
    "\n",
    "# for every 'fixed' version of the algorithm\n",
    "for args in versions:\n",
    "    print(data_strategy, args)\n",
    "\n",
    "    p = \"best_parameters/\" + algo_name + \"/\" + data_strategy + \"_\" + str(args) + \".pkl\"\n",
    "    if os.path.isfile(p):\n",
    "        print(\"We got them already\")\n",
    "        with open(p, \"rb\") as f:\n",
    "            best_params = pickle.load(f)\n",
    "    else:\n",
    "        print(\"We have to compute them now\")\n",
    "        # optimize for this fixed version\n",
    "        best_params = optimize_cornac(\n",
    "            ratings=ratings, algorithm_name=algo_name, args=args, max_evals=20\n",
    "        )\n",
    "\n",
    "        # save the best parameters for this fixed version\n",
    "\n",
    "        with open(\n",
    "            \"best_parameters/\"\n",
    "            + algo_name\n",
    "            + \"/\"\n",
    "            + data_strategy\n",
    "            + \"_\"\n",
    "            + str(args)\n",
    "            + \".pkl\",\n",
    "            \"wb\",\n",
    "        ) as f:\n",
    "            pickle.dump(best_params, f)\n",
    "\n",
    "    optimal_k = best_params[\"k\"]\n",
    "    optimal_reg = best_params[\"lambda_reg\"]\n",
    "    optimal_lr = best_params[\"learning_rate\"]\n",
    "\n",
    "    pop_biases_cornac, metrics_dict_cornac = modelling_mf.train_algorithm_cornac(\n",
    "        algorithm=algorithm_cornac(\n",
    "            k=optimal_k,\n",
    "            use_bias=args[\"bias\"],\n",
    "            lambda_reg=optimal_reg,\n",
    "            learning_rate=optimal_lr,\n",
    "        ),\n",
    "        algo_name=algo_name,\n",
    "        ratings=ratings,\n",
    "        evaluation_way=evaluation_way,\n",
    "        verbose=verbose,\n",
    "        n=nr_recs,\n",
    "        sampling_strategy=sampling_strategy,\n",
    "        partition_way=partition_way,\n",
    "        plot=plot,\n",
    "        data_strategy=data_strategy,\n",
    "        args=args,\n",
    "        save_plot=save_plot,\n",
    "    )\n",
    "\n",
    "    # Save metrics!\n",
    "    with open(\n",
    "        \"experimental_results/\"\n",
    "        + algo_name\n",
    "        + \"/\"\n",
    "        + data_strategy\n",
    "        + \"_\"\n",
    "        + str(args)\n",
    "        + \".pkl\",\n",
    "        \"wb\",\n",
    "    ) as f:\n",
    "        pickle.dump(metrics_dict_cornac, f)\n",
    "    with open('experimental_results/'+algo_name+'/detailed_per_item_'+data_strategy+'_'+str(args)+'.pkl', 'wb') as f:\n",
    "        pickle.dump(pop_biases_cornac, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c3278b04384a1f2d1b0bc3e8783905713abb1db8d84b3b69ddff13fab40f022"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "011270a38ead4978b49bb9ee56067e5e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "10ea70a980934b569123c30a37b9e2fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_dd3434354ad94760824f41bb99606606",
       "style": "IPY_MODEL_011270a38ead4978b49bb9ee56067e5e",
       "value": " 20/20 [00:01&lt;00:00, 26.39it/s, loss=306950.34]"
      }
     },
     "136df83d93ee4fb1bfc4bf38e13ff29d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_86ffae722f204073bf57bd3f6f90c71d",
       "style": "IPY_MODEL_227f110414164d09aa90476c4781486b",
       "value": "Rating:   0%"
      }
     },
     "1ebbd336c4a2436da84214367e7b3957": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "227f110414164d09aa90476c4781486b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "247651687cc046c08282fb358982347f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "365f970e328b4bf9af9b9208a31e633f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "37969bb696124539888ac0fc76da222f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "44193e27c6104ab5807d8caaee4fc347": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5095859ce5404821b13575f09bc236b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_37969bb696124539888ac0fc76da222f",
       "style": "IPY_MODEL_832af2bfa7254fae9d72316ff42a8081",
       "value": "100%"
      }
     },
     "52c9116a543c4f12a7db657837b64bc5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5f914311747544bd8b38f563cc27aa81": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7c19122a6b8d4fe09da01c2833fb4689": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_52c9116a543c4f12a7db657837b64bc5",
       "style": "IPY_MODEL_247651687cc046c08282fb358982347f",
       "value": " 0/39278 [00:00&lt;?, ?it/s]"
      }
     },
     "7d0b73dafc704acfaf365ee80f313f76": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_136df83d93ee4fb1bfc4bf38e13ff29d",
        "IPY_MODEL_9da83b4b55fc4af2bf942c829d17611c",
        "IPY_MODEL_7c19122a6b8d4fe09da01c2833fb4689"
       ],
       "layout": "IPY_MODEL_da1c82479b724268a0de376f4a8f9f5f"
      }
     },
     "832af2bfa7254fae9d72316ff42a8081": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "86ffae722f204073bf57bd3f6f90c71d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9d1ab03c199c4022b53f7b9e41931ed8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_44193e27c6104ab5807d8caaee4fc347",
       "max": 20,
       "style": "IPY_MODEL_365f970e328b4bf9af9b9208a31e633f",
       "value": 20
      }
     },
     "9da83b4b55fc4af2bf942c829d17611c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_b9c1fe48b52947fab400feaf7206ec35",
       "max": 39278,
       "style": "IPY_MODEL_1ebbd336c4a2436da84214367e7b3957"
      }
     },
     "a05daaf43450410aaf9419530a40dcbc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_5095859ce5404821b13575f09bc236b1",
        "IPY_MODEL_9d1ab03c199c4022b53f7b9e41931ed8",
        "IPY_MODEL_10ea70a980934b569123c30a37b9e2fe"
       ],
       "layout": "IPY_MODEL_5f914311747544bd8b38f563cc27aa81"
      }
     },
     "b9c1fe48b52947fab400feaf7206ec35": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "da1c82479b724268a0de376f4a8f9f5f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "dd3434354ad94760824f41bb99606606": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
