{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc80e674",
   "metadata": {},
   "source": [
    "# Steps\n",
    "1. Choose data scenario.\n",
    "2. Generate the dataset accordingly.\n",
    "5. Choose 'fixed' configuration.\n",
    "6. For each 'fixed' configuration, optimize the other parameters based on RMSE.\n",
    "7. Given optimal setting, run popularity bias analysis for every version of the 'fixed' configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d29498",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261f8b85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"TBB\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "# for random generation\n",
    "\n",
    "\n",
    "# basic functions\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_rows = 100\n",
    "import pickle\n",
    "\n",
    "# custom-made functions\n",
    "import modelling_mf\n",
    "from data_generation import generate_data\n",
    "from optimize_hp import optimize_lkpy, optimize_cornac\n",
    "\n",
    "\n",
    "# cornac RS library\n",
    "from cornac.models import bpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a89599-5004-4b31-ad70-939c012fccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lenskit_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cada525",
   "metadata": {},
   "source": [
    "## Fairbook data and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93470ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"fairbook\"\n",
    "# user-item interactions\n",
    "fairbook_ratings = pd.read_csv(\"data/\" + data + \"_events.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940275c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_col = \"user\"  # the name of the column that includes the users\n",
    "item_col = \"item\"  # the name of the column that includes the items\n",
    "predict_col = \"rating\"  # the name of the column that includes the interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8c854d",
   "metadata": {},
   "source": [
    "## Scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fa1baa",
   "metadata": {},
   "source": [
    "1. There is no general relation between popularity and rating: uniformly_random\n",
    "2. Popular items are rated higher by the users.: popularity_good\n",
    "3. Popular items are rated lower by the users.: popilarity_bad\n",
    "4. Popular items are rated higher by users with big profiles.: popularity_good_for_bp_ur\n",
    "5. Popular items are rated lower by users with big profiles.: popularity_bad_for_bp_ur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fad48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_strategies = [\n",
    "    \"uniformly_random\",\n",
    "    \"popularity_good\",\n",
    "    \"popularity_bad\",\n",
    "    \"popularity_good_for_bp_ur\",\n",
    "    \"popularity_bad_for_bp_ur\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e219eda1-c01f-4e60-9dfa-b8a4ad1f3a9c",
   "metadata": {},
   "source": [
    "## Optimize, train, evaluate LKPY\n",
    "- **Algorithm**\n",
    "- **Fixed parameters**\n",
    "- **To-optimize parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bee60f7-aac3-47e8-b59f-7d1606cd54c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_versions = {\n",
    "    \"BPR\": [\n",
    "        {\"bias\": True},\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b065681-33c1-45d1-a92f-b20a37304d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_way = \"cross_validation\"\n",
    "verbose = False\n",
    "plot = True\n",
    "save_plot = True  # save the plots\n",
    "fallback = False\n",
    "nr_recs = 10\n",
    "sampling_strategy = \"frac\"\n",
    "partition_way = \"user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7b8bae-58d3-4cfe-807c-70c101b5549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose algorithm\n",
    "algorithm_lkpy = lenskit_tf.BPR\n",
    "algo_name = \"BPR\"\n",
    "versions = algo_versions[algo_name]\n",
    "\n",
    "# for every data strategy\n",
    "for i in range(len(data_strategies)):\n",
    "    data_strategy = data_strategies[i]\n",
    "    # generate the data\n",
    "    ratings = generate_data(\n",
    "        strategy=data_strategy, copying_dataset=fairbook_ratings, user_perc=0.2\n",
    "    )\n",
    "\n",
    "    # for every 'fixed' version of the algorithm\n",
    "    for args in versions:\n",
    "        print(data_strategy, args)\n",
    "\n",
    "        # optimize for this fixed version\n",
    "        best_params = optimize_lkpy(\n",
    "            ratings=ratings,\n",
    "            algorithm_name=algo_name,\n",
    "            args=args,\n",
    "            partition_way=\"row\",\n",
    "            max_evals=20,\n",
    "        )\n",
    "\n",
    "        # save the best parameters for this fixed version\n",
    "\n",
    "        with open(\n",
    "            \"best_parameters/\"\n",
    "            + algo_name\n",
    "            + \"/\"\n",
    "            + data_strategy\n",
    "            + \"_\"\n",
    "            + str(args)\n",
    "            + \".pkl\",\n",
    "            \"wb\",\n",
    "        ) as f:\n",
    "            pickle.dump(best_params, f)\n",
    "\n",
    "        features_list = [10, 50, 100]  # check\n",
    "        optimal_features = features_list[best_params[\"features\"]]\n",
    "\n",
    "        reg_list = [0, 0.001, 0.01, 0.1]\n",
    "        optimal_reg = reg_list[best_params[\"reg\"]]\n",
    "\n",
    "        neg_weight_list = [True, False]\n",
    "        optimal_nw = neg_weight_list[best_params[\"neg_weight\"]]\n",
    "\n",
    "        # run the training and evaluation for the fixed version + the best other parameters\n",
    "        pop_biases_lkpy, metrics_dict_lkpy = modelling_mf.train_algorithm(\n",
    "            algorithm=algorithm_lkpy(\n",
    "                features=optimal_features,\n",
    "                reg=optimal_reg,\n",
    "                neg_weight=optimal_nw,\n",
    "                epochs=100,\n",
    "            ),\n",
    "            algo_name=algo_name,\n",
    "            ratings=ratings,\n",
    "            evaluation_way=evaluation_way,\n",
    "            verbose=verbose,\n",
    "            n=nr_recs,\n",
    "            sampling_strategy=sampling_strategy,\n",
    "            partition_way=partition_way,\n",
    "            plot=plot,\n",
    "            data_strategy=data_strategy,\n",
    "            args=args,\n",
    "            save_plot=save_plot,\n",
    "        )\n",
    "\n",
    "        # Save metrics!\n",
    "        with open(\n",
    "            \"experimental_results/\"\n",
    "            + algo_name\n",
    "            + \"/\"\n",
    "            + data_strategy\n",
    "            + \"_\"\n",
    "            + str(args)\n",
    "            + \".pkl\",\n",
    "            \"wb\",\n",
    "        ) as f:\n",
    "            pickle.dump(metrics_dict_lkpy, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e535cae7",
   "metadata": {},
   "source": [
    "## Optimize, train, evaluate Cornac\n",
    "- **Algorithm**\n",
    "- **Fixed parameters**\n",
    "- **To-optimize parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b407cd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_versions = {\"CornacBPR\": [{\"bias\": True}, {\"bias\": False}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f94627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_way = \"cross_validation\"\n",
    "verbose = False\n",
    "plot = True\n",
    "save_plot = True  # save the plots\n",
    "fallback = False\n",
    "nr_recs = 10\n",
    "sampling_strategy = \"frac\"\n",
    "partition_way = \"user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b31512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose algorithm\n",
    "algorithm_cornac = bpr.BPR\n",
    "algo_name = \"CornacBPR\"\n",
    "versions = algo_versions[algo_name]\n",
    "\n",
    "# for every data strategy\n",
    "for i in range(len(data_strategies)):\n",
    "    data_strategy = data_strategies[i]\n",
    "    # generate the data\n",
    "    ratings = generate_data(\n",
    "        strategy=data_strategy, copying_dataset=fairbook_ratings, user_perc=0.2\n",
    "    )\n",
    "\n",
    "    # for every 'fixed' version of the algorithm\n",
    "    for args in versions:\n",
    "        print(data_strategy, args)\n",
    "\n",
    "        # optimize for this fixed version\n",
    "        best_params = optimize_cornac(\n",
    "            ratings=ratings, algorithm_name=algo_name, args=args, max_evals=20\n",
    "        )\n",
    "\n",
    "        # save the best parameters for this fixed version\n",
    "\n",
    "        with open(\n",
    "            \"best_parameters/\"\n",
    "            + algo_name\n",
    "            + \"/\"\n",
    "            + data_strategy\n",
    "            + \"_\"\n",
    "            + str(args)\n",
    "            + \".pkl\",\n",
    "            \"wb\",\n",
    "        ) as f:\n",
    "            pickle.dump(best_params, f)\n",
    "\n",
    "        optimal_k = best_params[\"k\"]\n",
    "        optimal_reg = best_params[\"lambda_reg\"]\n",
    "        optimal_lr = best_params[\"learning_rate\"]\n",
    "\n",
    "        # run the training and evaluation for the fixed version + the best other parameters\n",
    "        pop_biases_cornac, metrics_dict_cornac = modelling_mf.train_algorithm_cornac(\n",
    "            algorithm=algorithm_cornac(\n",
    "                k=optimal_k,\n",
    "                lambda_reg=optimal_reg,\n",
    "                learning_rate=optimal_lr,\n",
    "                use_bias=args[\"bias\"],\n",
    "            ),\n",
    "            algo_name=algo_name,\n",
    "            ratings=ratings,\n",
    "            evaluation_way=evaluation_way,\n",
    "            verbose=verbose,\n",
    "            n=nr_recs,\n",
    "            sampling_strategy=sampling_strategy,\n",
    "            partition_way=partition_way,\n",
    "            plot=plot,\n",
    "            data_strategy=data_strategy,\n",
    "            args=args,\n",
    "            save_plot=save_plot,\n",
    "        )\n",
    "\n",
    "        # Save metrics!\n",
    "        with open(\n",
    "            \"experimental_results/\"\n",
    "            + algo_name\n",
    "            + \"/\"\n",
    "            + data_strategy\n",
    "            + \"_\"\n",
    "            + str(args)\n",
    "            + \".pkl\",\n",
    "            \"wb\",\n",
    "        ) as f:\n",
    "            pickle.dump(metrics_dict_cornac, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c3278b04384a1f2d1b0bc3e8783905713abb1db8d84b3b69ddff13fab40f022"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
